# modules/ai.py

import json
import os
import time
import asyncio
import aiohttp
from typing import Dict, List, Optional, Any
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import ContextTypes, MessageHandler, filters, CommandHandler, CallbackQueryHandler
from utils.decorators import error_handler, permission_check, module_check
from utils.text_utils import TextUtils

# æ¨¡å—å…ƒæ•°æ®
MODULE_NAME = "ai"
MODULE_VERSION = "1.0.0"
MODULE_DESCRIPTION = "AI èŠå¤©å°åŠ©æ‰‹"
MODULE_DEPENDENCIES = []
MODULE_COMMANDS = ["ai", "aiconfig", "aiclear", "aiwhitelist"]

# æ¨¡å—çŠ¶æ€
_state = {
    "providers": {},  # æœåŠ¡å•†é…ç½®
    "whitelist": [],  # ç™½åå•ç”¨æˆ· ID
    "conversations": {},  # ç”¨æˆ·å¯¹è¯ä¸Šä¸‹æ–‡
    "default_provider": None,  # é»˜è®¤æœåŠ¡å•†
    "last_save_time": 0,  # ä¸Šæ¬¡ä¿å­˜æ—¶é—´
    "usage_stats": {  # ä½¿ç”¨ç»Ÿè®¡
        "total_requests": 0,
        "requests_by_provider": {},
        "requests_by_user": {}
    },
    "conversation_timeout": 24 * 60 * 60,  # é»˜è®¤ 24 å°æ—¶è¶…æ—¶
}

# é…ç½®æ–‡ä»¶è·¯å¾„
_config_file = "config/ai_config.json"
# ä¸Šä¸‹æ–‡ä¿å­˜è·¯å¾„
_context_file = "data/ai_contexts.json"
# æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦
MAX_CONTEXT_LENGTH = 10
# æœ€å¤§è¯·æ±‚è¶…æ—¶æ—¶é—´ (ç§’)
REQUEST_TIMEOUT = 60
# æœ€å¤§æ¶ˆæ¯é•¿åº¦
MAX_MESSAGE_LENGTH = 4000
# æµå¼å¤„ç†é…ç½®
STREAM_CHUNK_SIZE = 15  # æ¯æ¬¡æ›´æ–°çš„å­—ç¬¦æ•°
MIN_UPDATE_INTERVAL = 0.5  # æœ€å°æ›´æ–°é—´éš”(ç§’)

# æœåŠ¡å•†é…ç½®æ¨¡æ¿
PROVIDER_TEMPLATES = {
    "openai": {
        "name": "OpenAI",
        "api_url": "https://api.openai.com/v1/chat/completions",
        "api_key": "",
        "model": "gpt-3.5-turbo",
        "temperature": 0.7,
        "system_prompt": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ã€‚",
        "request_format": "openai"
    },
    "gemini": {
        "name": "Google Gemini",
        "api_url":
        "https://generativelanguage.googleapis.com/v1/models/{model}:generateContent",
        "api_key": "",
        "model": "gemini-pro",
        "temperature": 0.7,
        "system_prompt": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ã€‚",
        "request_format": "gemini"
    },
    "anthropic": {
        "name": "Anthropic Claude",
        "api_url": "https://api.anthropic.com/v1/messages",
        "api_key": "",
        "model": "claude-3-opus-20240229",
        "temperature": 0.7,
        "system_prompt": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ã€‚",
        "request_format": "anthropic"
    },
    "custom": {
        "name": "è‡ªå®šä¹‰ API",
        "api_url": "",
        "api_key": "",
        "model": "",
        "temperature": 0.7,
        "system_prompt": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ã€‚",
        "request_format": "openai"
    }
}


# ä¸åŒæœåŠ¡å•†çš„è¯·æ±‚æ ¼å¼åŒ–å‡½æ•°
def format_openai_request(provider, messages, stream=False):
    """æ ¼å¼åŒ– OpenAI è¯·æ±‚"""
    return {
        "model": provider["model"],
        "messages": messages,
        "temperature": provider["temperature"],
        "stream": stream
    }


def format_gemini_request(provider, messages, stream=False):
    """æ ¼å¼åŒ– Gemini è¯·æ±‚"""
    # è½¬æ¢æ¶ˆæ¯æ ¼å¼ä¸º Gemini æ ¼å¼
    gemini_messages = []

    for msg in messages:
        role = msg["role"]
        content = msg["content"]

        if role == "system":
            # ç³»ç»Ÿæ¶ˆæ¯ä½œä¸ºç”¨æˆ·æ¶ˆæ¯çš„å‰ç¼€
            if gemini_messages and gemini_messages[-1]["role"] == "user":
                gemini_messages[-1]["parts"].append({"text": content})
            else:
                gemini_messages.append({
                    "role": "user",
                    "parts": [{
                        "text": content
                    }]
                })
        elif role == "user":
            gemini_messages.append({
                "role": "user",
                "parts": [{
                    "text": content
                }]
            })
        elif role == "assistant":
            gemini_messages.append({
                "role": "model",
                "parts": [{
                    "text": content
                }]
            })

    return {
        "contents": gemini_messages,
        "generationConfig": {
            "temperature": provider["temperature"]
        },
        "stream": stream
    }


def format_anthropic_request(provider, messages, stream=False):
    """æ ¼å¼åŒ– Anthropic è¯·æ±‚"""
    # æå–ç³»ç»Ÿæç¤º
    system = ""
    for msg in messages:
        if msg["role"] == "system":
            system = msg["content"]
            break

    # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
    anthropic_messages = []
    for msg in messages:
        if msg["role"] == "user":
            anthropic_messages.append({
                "role": "user",
                "content": msg["content"]
            })
        elif msg["role"] == "assistant":
            anthropic_messages.append({
                "role": "assistant",
                "content": msg["content"]
            })

    # æ„å»ºè¯·æ±‚
    request = {
        "model": provider["model"],
        "messages": anthropic_messages,
        "temperature": provider["temperature"],
        "max_tokens": 4000,  # å¯é…ç½®çš„æœ€å¤§ä»¤ç‰Œæ•°
        "stream": stream
    }

    # æ·»åŠ ç³»ç»Ÿæç¤º (å¦‚æœæœ‰)
    if system:
        request["system"] = system

    return request


# è¯·æ±‚æ ¼å¼æ˜ å°„
REQUEST_FORMATTERS = {
    "openai": format_openai_request,
    "gemini": format_gemini_request,
    "anthropic": format_anthropic_request
}


# ä¸åŒæœåŠ¡å•†çš„å“åº”è§£æå‡½æ•°
def parse_openai_response(response_json):
    """è§£æ OpenAI å“åº”"""
    try:
        return response_json["choices"][0]["message"]["content"]
    except (KeyError, IndexError):
        return None


def parse_gemini_response(response_json):
    """è§£æ Gemini å“åº”"""
    try:
        return response_json["candidates"][0]["content"]["parts"][0]["text"]
    except (KeyError, IndexError):
        return None


def parse_anthropic_response(response_json):
    """è§£æ Anthropic å“åº”"""
    try:
        return response_json["content"][0]["text"]
    except (KeyError, IndexError):
        return None


# å“åº”è§£æå™¨æ˜ å°„
RESPONSE_PARSERS = {
    "openai": parse_openai_response,
    "gemini": parse_gemini_response,
    "anthropic": parse_anthropic_response
}


async def call_ai_api_stream(provider_id, messages, module_interface,
                             update_callback):
    """æµå¼è°ƒç”¨ AI API"""
    global _state

    if provider_id not in _state["providers"]:
        return "é”™è¯¯ï¼šæœªæ‰¾åˆ°æŒ‡å®šçš„æœåŠ¡å•†é…ç½®"

    provider = _state["providers"][provider_id]

    # æ£€æŸ¥ API å¯†é’¥
    if not provider.get("api_key"):
        return "é”™è¯¯ï¼šæœªé…ç½® API å¯†é’¥"

    # è·å–è¯·æ±‚æ ¼å¼åŒ–å™¨
    request_format = provider.get("request_format", "openai")
    formatter = REQUEST_FORMATTERS.get(request_format)
    if not formatter:
        return f"é”™è¯¯ï¼šä¸æ”¯æŒçš„è¯·æ±‚æ ¼å¼ {request_format}"

    # æ ¼å¼åŒ–è¯·æ±‚ (å¯ç”¨æµå¼)
    request_data = formatter(provider, messages, stream=True)

    # å‡†å¤‡ API URL
    api_url = provider["api_url"]
    if "{model}" in api_url:
        api_url = api_url.replace("{model}", provider["model"])

    # å‡†å¤‡è¯·æ±‚å¤´
    headers = {"Content-Type": "application/json"}

    # ä¸åŒæœåŠ¡å•†çš„è®¤è¯æ–¹å¼
    if request_format == "openai":
        headers["Authorization"] = f"Bearer {provider['api_key']}"
    elif request_format == "gemini":
        # Gemini ä½¿ç”¨ URL å‚æ•°ä¼ é€’ API å¯†é’¥
        api_url = f"{api_url}?key={provider['api_key']}"
    elif request_format == "anthropic":
        headers["x-api-key"] = provider["api_key"]
        headers["anthropic-version"] = "2023-06-01"

    try:
        module_interface.logger.debug(f"æ­£åœ¨æµå¼è°ƒç”¨ {provider['name']} API")

        full_response = ""
        last_update_time = time.time()

        async with aiohttp.ClientSession() as session:
            async with session.post(api_url,
                                    json=request_data,
                                    headers=headers,
                                    timeout=REQUEST_TIMEOUT) as response:
                if response.status != 200:
                    error_text = await response.text()
                    module_interface.logger.error(
                        f"API è¯·æ±‚å¤±è´¥: {response.status} - {error_text}")
                    return f"API è¯·æ±‚å¤±è´¥: HTTP {response.status}"

                # æ ¹æ®ä¸åŒæœåŠ¡å•†å¤„ç†æµå¼å“åº”
                if request_format == "openai":
                    # OpenAI æµå¼å“åº”å¤„ç†
                    async for line in response.content:
                        line = line.strip()
                        if not line or line == b'data: [DONE]':
                            continue

                        try:
                            # ç§»é™¤ "data: " å‰ç¼€å¹¶è§£æ JSON
                            if line.startswith(b'data: '):
                                json_data = json.loads(line[6:])

                                if 'choices' in json_data and json_data[
                                        'choices']:
                                    delta = json_data['choices'][0].get(
                                        'delta', {})
                                    if 'content' in delta and delta['content']:
                                        content = delta['content']
                                        full_response += content

                                        # ç¡®ä¿æœ‰å†…å®¹æ‰æ›´æ–°
                                        if full_response.strip():
                                            # æ§åˆ¶æ›´æ–°é¢‘ç‡
                                            current_time = time.time()
                                            if current_time - last_update_time >= MIN_UPDATE_INTERVAL:
                                                await update_callback(
                                                    full_response)
                                                last_update_time = current_time
                        except Exception as e:
                            module_interface.logger.error(f"è§£ææµå¼å“åº”å¤±è´¥: {e}")

                elif request_format == "anthropic":
                    # Anthropic æµå¼å“åº”å¤„ç†
                    async for line in response.content:
                        line = line.strip()
                        if not line or line == b'data: [DONE]':
                            continue

                        try:
                            # ç§»é™¤ "data: " å‰ç¼€å¹¶è§£æ JSON
                            if line.startswith(b'data: '):
                                json_data = json.loads(line[6:])

                                if 'type' in json_data and json_data[
                                        'type'] == 'content_block_delta':
                                    delta = json_data.get('delta', {})
                                    if 'text' in delta and delta['text']:
                                        content = delta['text']
                                        full_response += content

                                        # ç¡®ä¿æœ‰å†…å®¹æ‰æ›´æ–°
                                        if full_response.strip():
                                            # æ§åˆ¶æ›´æ–°é¢‘ç‡
                                            current_time = time.time()
                                            if current_time - last_update_time >= MIN_UPDATE_INTERVAL:
                                                await update_callback(
                                                    full_response)
                                                last_update_time = current_time
                        except Exception as e:
                            module_interface.logger.error(f"è§£ææµå¼å“åº”å¤±è´¥: {e}")

                elif request_format == "gemini":
                    # Gemini æµå¼å“åº”å¤„ç†
                    buffer = b""

                    async for chunk in response.content:
                        buffer += chunk

                        # å°è¯•è§£æå®Œæ•´çš„ JSON å¯¹è±¡
                        if b'\n' in buffer:
                            lines = buffer.split(b'\n')
                            # ä¿ç•™æœ€åä¸€ä¸ªå¯èƒ½ä¸å®Œæ•´çš„è¡Œ
                            buffer = lines.pop()

                            for line in lines:
                                if not line.strip():
                                    continue

                                try:
                                    json_data = json.loads(line)

                                    # æå–æ–‡æœ¬å†…å®¹
                                    if 'candidates' in json_data and json_data[
                                            'candidates']:
                                        candidate = json_data['candidates'][0]
                                        if 'content' in candidate and 'parts' in candidate[
                                                'content']:
                                            for part in candidate['content'][
                                                    'parts']:
                                                if 'text' in part and part[
                                                        'text']:
                                                    content = part['text']
                                                    full_response += content

                                                    # åªæœ‰å½“æœ‰å®é™…å†…å®¹æ—¶æ‰æ›´æ–°
                                                    if full_response.strip():
                                                        # æ§åˆ¶æ›´æ–°é¢‘ç‡
                                                        current_time = time.time(
                                                        )
                                                        if current_time - last_update_time >= MIN_UPDATE_INTERVAL:
                                                            await update_callback(
                                                                full_response)
                                                            last_update_time = current_time
                                except Exception as e:
                                    module_interface.logger.error(
                                        f"è§£æ Gemini æµå¼å“åº”å¤±è´¥: {e} - è¡Œ: {line}")

                # ç¡®ä¿å®Œæ•´å“åº”è¢«å‘é€
                if full_response:
                    await update_callback(full_response)

        # æ›´æ–°ä½¿ç”¨ç»Ÿè®¡
        _state["usage_stats"]["total_requests"] += 1
        _state["usage_stats"]["requests_by_provider"][
            provider_id] = _state["usage_stats"]["requests_by_provider"].get(
                provider_id, 0) + 1

        return full_response

    except aiohttp.ClientError as e:
        module_interface.logger.error(f"API è¯·æ±‚é”™è¯¯: {str(e)}")
        return f"API è¯·æ±‚é”™è¯¯: {str(e)}"
    except asyncio.TimeoutError:
        module_interface.logger.error("API è¯·æ±‚è¶…æ—¶")
        return "API è¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åå†è¯•"
    except Exception as e:
        module_interface.logger.error(f"è°ƒç”¨ AI API æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        return f"å‘ç”Ÿé”™è¯¯: {str(e)}"


async def call_ai_api(provider_id,
                      messages,
                      module_interface,
                      use_stream=False):
    """è°ƒç”¨ AI APIï¼Œå¯é€‰æ˜¯å¦ä½¿ç”¨æµå¼æ¨¡å¼"""
    if use_stream:
        # å½“ä½¿ç”¨æµå¼æ¨¡å¼ä½†æ²¡æœ‰å›è°ƒæ—¶ï¼Œåˆ›å»ºä¸€ä¸ªç©ºå›è°ƒ
        async def dummy_callback(_):
            pass

        return await call_ai_api_stream(provider_id, messages,
                                        module_interface, dummy_callback)

    # ä»¥ä¸‹æ˜¯åŸå§‹çš„éæµå¼å®ç°
    global _state

    if provider_id not in _state["providers"]:
        return "é”™è¯¯ï¼šæœªæ‰¾åˆ°æŒ‡å®šçš„æœåŠ¡å•†é…ç½®"

    provider = _state["providers"][provider_id]

    # æ£€æŸ¥ API å¯†é’¥
    if not provider.get("api_key"):
        return "é”™è¯¯ï¼šæœªé…ç½® API å¯†é’¥"

    # è·å–è¯·æ±‚æ ¼å¼åŒ–å™¨
    request_format = provider.get("request_format", "openai")
    formatter = REQUEST_FORMATTERS.get(request_format)
    if not formatter:
        return f"é”™è¯¯ï¼šä¸æ”¯æŒçš„è¯·æ±‚æ ¼å¼ {request_format}"

    # æ ¼å¼åŒ–è¯·æ±‚
    request_data = formatter(provider, messages, stream=False)

    # å‡†å¤‡ API URL
    api_url = provider["api_url"]
    if "{model}" in api_url:
        api_url = api_url.replace("{model}", provider["model"])

    # å‡†å¤‡è¯·æ±‚å¤´
    headers = {"Content-Type": "application/json"}

    # ä¸åŒæœåŠ¡å•†çš„è®¤è¯æ–¹å¼
    if request_format == "openai":
        headers["Authorization"] = f"Bearer {provider['api_key']}"
    elif request_format == "gemini":
        # Gemini ä½¿ç”¨ URL å‚æ•°ä¼ é€’ API å¯†é’¥
        api_url = f"{api_url}?key={provider['api_key']}"
    elif request_format == "anthropic":
        headers["x-api-key"] = provider["api_key"]
        headers["anthropic-version"] = "2023-06-01"

    try:
        module_interface.logger.debug(f"æ­£åœ¨è°ƒç”¨ {provider['name']} API")

        async with aiohttp.ClientSession() as session:
            async with session.post(api_url,
                                    json=request_data,
                                    headers=headers,
                                    timeout=REQUEST_TIMEOUT) as response:
                if response.status != 200:
                    error_text = await response.text()
                    module_interface.logger.error(
                        f"API è¯·æ±‚å¤±è´¥: {response.status} - {error_text}")
                    return f"API è¯·æ±‚å¤±è´¥: HTTP {response.status}"

                response_json = await response.json()

                # è·å–å“åº”è§£æå™¨
                parser = RESPONSE_PARSERS.get(request_format)
                if not parser:
                    return f"é”™è¯¯ï¼šä¸æ”¯æŒçš„å“åº”æ ¼å¼ {request_format}"

                # è§£æå“åº”
                result = parser(response_json)
                if result is None:
                    module_interface.logger.error(
                        f"è§£æ API å“åº”å¤±è´¥: {response_json}")
                    return "è§£æ API å“åº”å¤±è´¥"

                # æ›´æ–°ä½¿ç”¨ç»Ÿè®¡
                _state["usage_stats"]["total_requests"] += 1
                _state["usage_stats"]["requests_by_provider"][
                    provider_id] = _state["usage_stats"][
                        "requests_by_provider"].get(provider_id, 0) + 1

                return result

    except aiohttp.ClientError as e:
        module_interface.logger.error(f"API è¯·æ±‚é”™è¯¯: {str(e)}")
        return f"API è¯·æ±‚é”™è¯¯: {str(e)}"
    except asyncio.TimeoutError:
        module_interface.logger.error("API è¯·æ±‚è¶…æ—¶")
        return "API è¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åå†è¯•"
    except Exception as e:
        module_interface.logger.error(f"è°ƒç”¨ AI API æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        return f"å‘ç”Ÿé”™è¯¯: {str(e)}"


async def send_long_message(update, text, module_interface):
    """åˆ†æ®µå‘é€é•¿æ¶ˆæ¯"""
    # Telegram æ¶ˆæ¯æœ€å¤§é•¿åº¦çº¦ä¸º 4096 å­—ç¬¦
    MAX_LENGTH = 4000

    if len(text) <= MAX_LENGTH:
        return await update.message.reply_text(text)

    parts = []
    for i in range(0, len(text), MAX_LENGTH):
        parts.append(text[i:i + MAX_LENGTH])

    module_interface.logger.info(f"æ¶ˆæ¯è¿‡é•¿ï¼Œå°†åˆ†ä¸º {len(parts)} æ®µå‘é€")

    # å‘é€ç¬¬ä¸€æ®µ
    first_message = await update.message.reply_text(parts[0])

    # å‘é€å‰©ä½™æ®µè½
    for part in parts[1:]:
        await first_message.reply_text(part)

    return first_message


def _get_module_interface():
    """è·å–æ¨¡å—æ¥å£ï¼ˆè¾…åŠ©å‡½æ•°ï¼‰"""
    try:
        from telegram.ext import ApplicationBuilder
        application = ApplicationBuilder().token("dummy").build()
        bot_engine = application.bot_data.get("bot_engine")
        if bot_engine:
            return bot_engine.module_loader.get_module_interface(MODULE_NAME)
    except:
        pass
    return None


def get_user_context(user_id):
    """è·å–ç”¨æˆ·çš„å¯¹è¯ä¸Šä¸‹æ–‡"""
    global _state
    user_id_str = str(user_id)

    if user_id_str not in _state["conversations"]:
        # åˆå§‹åŒ–æ–°ç”¨æˆ·çš„ä¸Šä¸‹æ–‡
        _state["conversations"][user_id_str] = []

    return _state["conversations"][user_id_str]


def add_message_to_context(user_id, role, content):
    """æ·»åŠ æ¶ˆæ¯åˆ°ç”¨æˆ·ä¸Šä¸‹æ–‡"""
    global _state
    user_id_str = str(user_id)
    context = get_user_context(user_id_str)

    # æ·»åŠ æ–°æ¶ˆæ¯
    context.append({
        "role": role,
        "content": content,
        "timestamp": time.time()
    })

    # é™åˆ¶ä¸Šä¸‹æ–‡é•¿åº¦
    if len(context) > MAX_CONTEXT_LENGTH * 2:  # æˆå¯¹é™åˆ¶ (ç”¨æˆ·+åŠ©æ‰‹)
        # ä¿ç•™ç³»ç»Ÿæ¶ˆæ¯ (å¦‚æœæœ‰) å’Œæœ€è¿‘çš„æ¶ˆæ¯
        system_messages = [msg for msg in context if msg["role"] == "system"]
        recent_messages = context[-MAX_CONTEXT_LENGTH * 2:]
        context = system_messages + recent_messages
        _state["conversations"][user_id_str] = context

    # æ›´æ–°ç”¨æˆ·ç»Ÿè®¡
    if role == "user":
        _state["usage_stats"]["requests_by_user"][
            user_id_str] = _state["usage_stats"]["requests_by_user"].get(
                user_id_str, 0) + 1

    # ä¿å­˜ä¸Šä¸‹æ–‡
    save_contexts()

    return context


def clear_user_context(user_id):
    """æ¸…é™¤ç”¨æˆ·çš„å¯¹è¯ä¸Šä¸‹æ–‡"""
    global _state
    user_id_str = str(user_id)

    if user_id_str in _state["conversations"]:
        # ä¿ç•™ç³»ç»Ÿæç¤º
        system_messages = [
            msg for msg in _state["conversations"][user_id_str]
            if msg["role"] == "system"
        ]
        _state["conversations"][user_id_str] = system_messages
        save_contexts()
        return True

    return False


def cleanup_expired_conversations():
    """æ¸…ç†è¿‡æœŸçš„å¯¹è¯"""
    global _state
    now = time.time()
    timeout = _state.get("conversation_timeout", 24 * 60 * 60)  # é»˜è®¤24å°æ—¶
    expired_count = 0

    for user_id, context in list(_state["conversations"].items()):
        if not context:
            continue

        # è·å–æœ€åä¸€æ¡æ¶ˆæ¯çš„æ—¶é—´
        last_message_time = max([msg.get("timestamp", 0)
                                 for msg in context]) if context else 0

        # å¦‚æœè¶…è¿‡è¶…æ—¶æ—¶é—´ï¼Œæ¸…é™¤å¯¹è¯ï¼ˆä¿ç•™ç³»ç»Ÿæ¶ˆæ¯ï¼‰
        if now - last_message_time > timeout:
            system_messages = [
                msg for msg in context if msg["role"] == "system"
            ]
            _state["conversations"][user_id] = system_messages
            expired_count += 1

    return expired_count


def format_context_for_api(provider, user_id):
    """æ ¼å¼åŒ–ç”¨æˆ·ä¸Šä¸‹æ–‡ä¸º API è¯·æ±‚æ ¼å¼"""
    provider_data = _state["providers"].get(provider)
    if not provider_data:
        return []

    # è·å–ç”¨æˆ·ä¸Šä¸‹æ–‡
    context = get_user_context(user_id)

    # æ·»åŠ ç³»ç»Ÿæç¤ºä½œä¸ºç¬¬ä¸€æ¡æ¶ˆæ¯ (å¦‚æœä¸å­˜åœ¨)
    has_system = any(msg["role"] == "system" for msg in context)

    messages = []
    if not has_system and provider_data.get("system_prompt"):
        messages.append({
            "role": "system",
            "content": provider_data["system_prompt"]
        })

    # æ·»åŠ ä¸Šä¸‹æ–‡æ¶ˆæ¯ (å»æ‰æ—¶é—´æˆ³)
    for msg in context:
        if msg["role"] in ["user", "assistant", "system"]:
            messages.append({"role": msg["role"], "content": msg["content"]})

    return messages


def save_contexts():
    """ä¿å­˜æ‰€æœ‰ç”¨æˆ·çš„å¯¹è¯ä¸Šä¸‹æ–‡"""
    try:
        os.makedirs(os.path.dirname(_context_file), exist_ok=True)
        with open(_context_file, 'w', encoding='utf-8') as f:
            json.dump(_state["conversations"], f, ensure_ascii=False, indent=2)

        # æ›´æ–°ä¿å­˜æ—¶é—´
        _state["last_save_time"] = time.time()
    except Exception as e:
        module_interface = _get_module_interface()
        if module_interface:
            module_interface.logger.error(f"ä¿å­˜å¯¹è¯ä¸Šä¸‹æ–‡å¤±è´¥: {e}")


def load_contexts():
    """åŠ è½½æ‰€æœ‰ç”¨æˆ·çš„å¯¹è¯ä¸Šä¸‹æ–‡"""
    global _state

    if not os.path.exists(_context_file):
        return

    try:
        with open(_context_file, 'r', encoding='utf-8') as f:
            _state["conversations"] = json.load(f)
    except Exception as e:
        module_interface = _get_module_interface()
        if module_interface:
            module_interface.logger.error(f"åŠ è½½å¯¹è¯ä¸Šä¸‹æ–‡å¤±è´¥: {e}")


def save_config():
    """ä¿å­˜ AI é…ç½®"""
    global _state

    config_to_save = {
        "providers": _state["providers"],
        "whitelist": _state["whitelist"],
        "default_provider": _state["default_provider"],
        "usage_stats": _state["usage_stats"],
        "conversation_timeout": _state.get("conversation_timeout",
                                           24 * 60 * 60)
    }

    os.makedirs(os.path.dirname(_config_file), exist_ok=True)

    try:
        with open(_config_file, 'w', encoding='utf-8') as f:
            json.dump(config_to_save, f, ensure_ascii=False, indent=2)
    except Exception as e:
        module_interface = _get_module_interface()
        if module_interface:
            module_interface.logger.error(f"ä¿å­˜ AI é…ç½®å¤±è´¥: {e}")


def load_config():
    """åŠ è½½ AI é…ç½®"""
    global _state

    if not os.path.exists(_config_file):
        # ä¸è‡ªåŠ¨åˆ›å»ºé»˜è®¤æœåŠ¡å•†ï¼Œåªåˆå§‹åŒ–ç©ºç»“æ„
        _state["providers"] = {}
        _state["whitelist"] = []
        _state["default_provider"] = None
        _state["usage_stats"] = {
            "total_requests": 0,
            "requests_by_provider": {},
            "requests_by_user": {}
        }
        _state["conversation_timeout"] = 24 * 60 * 60  # é»˜è®¤ 24 å°æ—¶

        # åˆ›å»ºé…ç½®æ–‡ä»¶
        save_config()
        return

    try:
        with open(_config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)

            # åŠ è½½æä¾›å•†é…ç½®
            if "providers" in config:
                _state["providers"] = config["providers"]

            # åŠ è½½ç™½åå•
            if "whitelist" in config:
                _state["whitelist"] = config["whitelist"]

            # åŠ è½½é»˜è®¤æä¾›å•†
            if "default_provider" in config:
                _state["default_provider"] = config["default_provider"]

            # åŠ è½½ä½¿ç”¨ç»Ÿè®¡
            if "usage_stats" in config:
                _state["usage_stats"] = config["usage_stats"]

            # åŠ è½½å¯¹è¯è¶…æ—¶è®¾ç½®
            if "conversation_timeout" in config:
                _state["conversation_timeout"] = config["conversation_timeout"]
    except Exception as e:
        module_interface = _get_module_interface()
        if module_interface:
            module_interface.logger.error(f"åŠ è½½ AI é…ç½®å¤±è´¥: {e}")


def is_super_admin(user_id, context):
    """æ£€æŸ¥ç”¨æˆ·æ˜¯å¦ä¸ºè¶…çº§ç®¡ç†å‘˜"""
    try:
        # ä½¿ç”¨ config_manager æ£€æŸ¥ç®¡ç†å‘˜æƒé™
        config_manager = context.bot_data.get("config_manager")
        if config_manager:
            return config_manager.is_admin(user_id)
    except Exception as e:
        module_interface = _get_module_interface()
        if module_interface:
            module_interface.logger.error(f"æ£€æŸ¥è¶…çº§ç®¡ç†å‘˜æƒé™æ—¶å‡ºé”™: {e}")
    return False


def is_whitelisted(user_id):
    """æ£€æŸ¥ç”¨æˆ·æ˜¯å¦åœ¨ç™½åå•ä¸­"""
    global _state
    return int(user_id) in _state["whitelist"]


def can_use_ai(user_id, chat_type, context):
    """æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å¯ä»¥ä½¿ç”¨ AI åŠŸèƒ½"""
    # è½¬æ¢ä¸ºæ•´æ•° ID
    user_id = int(user_id)

    # è¶…çº§ç®¡ç†å‘˜æ€»æ˜¯å¯ä»¥ä½¿ç”¨
    config_manager = context.bot_data.get("config_manager")
    if config_manager and config_manager.is_admin(user_id):
        return True

    # ç™½åå•ç”¨æˆ·å¯ä»¥ä½¿ç”¨
    if is_whitelisted(user_id):
        return True

    # å…¶ä»–ç”¨æˆ·ä¸èƒ½ä½¿ç”¨
    return False


@error_handler
@permission_check(admin_only="super_admin")
async def ai_config_command(update: Update,
                            context: ContextTypes.DEFAULT_TYPE):
    """å¤„ç† /aiconfig å‘½ä»¤ - é…ç½® AI è®¾ç½®"""
    # è·å–æ¨¡å—æ¥å£
    module_interface = context.bot_data[
        "bot_engine"].module_loader.get_module_interface(MODULE_NAME)

    # æ£€æŸ¥æ˜¯å¦æ˜¯ç§èŠ
    if update.effective_chat.type != "private":
        await update.message.reply_text("âš ï¸ å‡ºäºå®‰å…¨è€ƒè™‘ï¼ŒAI é…ç½®åªèƒ½åœ¨ç§èŠä¸­è¿›è¡Œ")
        return

    # è§£æå‚æ•°
    if not context.args:
        # æ˜¾ç¤ºå½“å‰é…ç½®
        await show_ai_config(update, context)
        return

    # é…ç½®å‘½ä»¤æ ¼å¼: /aiconfig <æ“ä½œ> [å‚æ•°...]
    operation = context.args[0].lower()

    if operation == "provider":
        # é…ç½®æœåŠ¡å•†: /aiconfig provider <provider_id> <å‚æ•°> <å€¼>
        if len(context.args) < 4:
            await update.message.reply_text(
                "ç”¨æ³•: `/aiconfig provider <provider_id> <å‚æ•°> <å€¼>`\n"
                "å‚æ•°å¯ä»¥æ˜¯: name, api\\_url, api\\_key, model, temperature, system\\_prompt, request\\_format",
                parse_mode="MARKDOWN")
            return

        provider_id = context.args[1]
        param = context.args[2]
        value = " ".join(context.args[3:])

        # æ£€æŸ¥æœåŠ¡å•†æ˜¯å¦å­˜åœ¨
        if provider_id not in _state[
                "providers"] and provider_id not in PROVIDER_TEMPLATES:
            await update.message.reply_text(f"æœªçŸ¥çš„æœåŠ¡å•† ID: `{provider_id}`",
                                            parse_mode="MARKDOWN")
            return

        # å¦‚æœæ˜¯æ–°æœåŠ¡å•†ï¼Œä»æ¨¡æ¿åˆ›å»º
        if provider_id not in _state["providers"]:
            if provider_id in PROVIDER_TEMPLATES:
                _state["providers"][provider_id] = PROVIDER_TEMPLATES[
                    provider_id].copy()
            else:
                _state["providers"][provider_id] = PROVIDER_TEMPLATES[
                    "custom"].copy()
                _state["providers"][provider_id]["name"] = provider_id

        # æ›´æ–°å‚æ•°
        valid_params = [
            "name", "api_url", "api_key", "model", "temperature",
            "system_prompt", "request_format"
        ]

        if param not in valid_params:
            # è½¬ä¹‰å‚æ•°åç§°ï¼Œé˜²æ­¢è¢«è§£é‡Šä¸º Markdown æ ¼å¼
            valid_params_escaped = [
                p.replace("_", "\\_") for p in valid_params
            ]
            await update.message.reply_text(
                f"æ— æ•ˆçš„å‚æ•°: `{param}`\n"
                f"æœ‰æ•ˆå‚æ•°: {', '.join(valid_params_escaped)}",
                parse_mode="MARKDOWN")
            return

        # ç‰¹æ®Šå¤„ç† temperature (è½¬æ¢ä¸ºæµ®ç‚¹æ•°)
        if param == "temperature":
            try:
                value = float(value)
                if not (0.0 <= value <= 1.0):
                    await update.message.reply_text(
                        "temperature å¿…é¡»åœ¨ 0.0 åˆ° 1.0 ä¹‹é—´")
                    return
            except ValueError:
                await update.message.reply_text("temperature å¿…é¡»æ˜¯æœ‰æ•ˆçš„æµ®ç‚¹æ•°")
                return

        # æ›´æ–°å‚æ•°
        _state["providers"][provider_id][param] = value

        # ä¿å­˜é…ç½®
        save_config()

        await update.message.reply_text(
            f"âœ… å·²æ›´æ–°æœåŠ¡å•† `{provider_id}` çš„ `{param}` å‚æ•°", parse_mode="MARKDOWN")
        module_interface.logger.info(
            f"ç”¨æˆ· {update.effective_user.id} æ›´æ–°äº†æœåŠ¡å•† {provider_id} çš„ {param} å‚æ•°")

    elif operation == "default":
        # è®¾ç½®é»˜è®¤æœåŠ¡å•†: /aiconfig default <provider_id>
        if len(context.args) < 2:
            await update.message.reply_text(
                "ç”¨æ³•: `/aiconfig default <provider_id>`", parse_mode="MARKDOWN")
            return

        provider_id = context.args[1]

        # æ£€æŸ¥æœåŠ¡å•†æ˜¯å¦å­˜åœ¨
        if provider_id not in _state["providers"]:
            await update.message.reply_text(f"æœªçŸ¥çš„æœåŠ¡å•† ID: `{provider_id}`",
                                            parse_mode="MARKDOWN")
            return

        # æ›´æ–°é»˜è®¤æœåŠ¡å•†
        _state["default_provider"] = provider_id

        # ä¿å­˜é…ç½®
        save_config()

        await update.message.reply_text(f"âœ… å·²å°†é»˜è®¤æœåŠ¡å•†è®¾ç½®ä¸º: `{provider_id}`",
                                        parse_mode="MARKDOWN")
        module_interface.logger.info(
            f"ç”¨æˆ· {update.effective_user.id} å°†é»˜è®¤æœåŠ¡å•†è®¾ç½®ä¸º {provider_id}")

    elif operation == "delete":
        # åˆ é™¤æœåŠ¡å•†: /aiconfig delete <provider_id>
        if len(context.args) < 2:
            await update.message.reply_text(
                "ç”¨æ³•: `/aiconfig delete <provider_id>`", parse_mode="MARKDOWN")
            return

        provider_id = context.args[1]

        # æ£€æŸ¥æœåŠ¡å•†æ˜¯å¦å­˜åœ¨
        if provider_id not in _state["providers"]:
            await update.message.reply_text(f"æœªçŸ¥çš„æœåŠ¡å•† ID: `{provider_id}`",
                                            parse_mode="MARKDOWN")
            return

        # å¦‚æœåˆ é™¤çš„æ˜¯é»˜è®¤æœåŠ¡å•†ï¼Œé‡ç½®é»˜è®¤æœåŠ¡å•†
        if _state["default_provider"] == provider_id:
            _state["default_provider"] = None

        # åˆ é™¤æœåŠ¡å•†
        del _state["providers"][provider_id]

        # ä¿å­˜é…ç½®
        save_config()

        await update.message.reply_text(f"âœ… å·²åˆ é™¤æœåŠ¡å•†: `{provider_id}`",
                                        parse_mode="MARKDOWN")
        module_interface.logger.info(
            f"ç”¨æˆ· {update.effective_user.id} åˆ é™¤äº†æœåŠ¡å•† {provider_id}")

    elif operation == "new":
        # åˆ›å»ºæ–°æœåŠ¡å•†: /aiconfig new <provider_id> [template]
        if len(context.args) < 2:
            await update.message.reply_text(
                "ç”¨æ³•: `/aiconfig new <provider_id> [template]`\n"
                f"å¯ç”¨æ¨¡æ¿: {', '.join(PROVIDER_TEMPLATES.keys())}",
                parse_mode="MARKDOWN")
            return

        provider_id = context.args[1]
        template = context.args[2] if len(context.args) > 2 else "custom"

        # æ£€æŸ¥æœåŠ¡å•† ID æ˜¯å¦å·²å­˜åœ¨
        if provider_id in _state["providers"]:
            await update.message.reply_text(f"æœåŠ¡å•† ID å·²å­˜åœ¨: `{provider_id}`",
                                            parse_mode="MARKDOWN")
            return

        # æ£€æŸ¥æ¨¡æ¿æ˜¯å¦å­˜åœ¨
        if template not in PROVIDER_TEMPLATES:
            await update.message.reply_text(
                f"æœªçŸ¥çš„æ¨¡æ¿: `{template}`\n"
                f"å¯ç”¨æ¨¡æ¿: {', '.join(PROVIDER_TEMPLATES.keys())}",
                parse_mode="MARKDOWN")
            return

        # åˆ›å»ºæ–°æœåŠ¡å•†
        _state["providers"][provider_id] = PROVIDER_TEMPLATES[template].copy()
        _state["providers"][provider_id]["name"] = provider_id

        # å¦‚æœæ²¡æœ‰é»˜è®¤æœåŠ¡å•†ï¼Œè®¾ç½®ä¸ºé»˜è®¤
        if not _state["default_provider"]:
            _state["default_provider"] = provider_id

        # ä¿å­˜é…ç½®
        save_config()

        await update.message.reply_text(
            f"âœ… å·²åˆ›å»ºæ–°æœåŠ¡å•†: `{provider_id}` (ä½¿ç”¨ {template} æ¨¡æ¿)\n"
            f"è¯·ä½¿ç”¨ `/aiconfig provider {provider_id} api_key YOUR_API_KEY` è®¾ç½® API å¯†é’¥",
            parse_mode="MARKDOWN")
        module_interface.logger.info(
            f"ç”¨æˆ· {update.effective_user.id} åˆ›å»ºäº†æ–°æœåŠ¡å•† {provider_id}")

    elif operation == "test":
        # æµ‹è¯•æœåŠ¡å•†: /aiconfig test <provider_id>
        if len(context.args) < 2:
            await update.message.reply_text(
                "ç”¨æ³•: `/aiconfig test <provider_id>`", parse_mode="MARKDOWN")
            return

        provider_id = context.args[1]

        # æ£€æŸ¥æœåŠ¡å•†æ˜¯å¦å­˜åœ¨
        if provider_id not in _state["providers"]:
            await update.message.reply_text(f"æœªçŸ¥çš„æœåŠ¡å•† ID: `{provider_id}`",
                                            parse_mode="MARKDOWN")
            return

        # å‘é€æµ‹è¯•æ¶ˆæ¯
        await update.message.reply_text(f"ğŸ”„ æ­£åœ¨æµ‹è¯•æœåŠ¡å•† `{provider_id}`...",
                                        parse_mode="MARKDOWN")

        # å‡†å¤‡æµ‹è¯•æ¶ˆæ¯
        test_messages = [{
            "role": "user",
            "content": "Hello, can you tell me what time is it?"
        }]

        # è°ƒç”¨ API
        response = await call_ai_api(provider_id, test_messages,
                                     module_interface)

        # æ˜¾ç¤ºå“åº” - ä½¿ç”¨ HTML æ¸²æŸ“
        try:
            # ä½¿ç”¨ HTML æ ¼å¼å‘é€å“åº”
            html_response = TextUtils.markdown_to_html(
                f"ğŸ“ æµ‹è¯•ç»“æœ:\n\n{response}")
            await update.message.reply_text(html_response, parse_mode="HTML")
        except Exception as e:
            module_interface.logger.error(f"HTML æ¸²æŸ“æµ‹è¯•ç»“æœå¤±è´¥: {e}")
            # å›é€€åˆ°çº¯æ–‡æœ¬
            await update.message.reply_text(f"ğŸ“ æµ‹è¯•ç»“æœ:\n\n{response}")

        module_interface.logger.info(
            f"ç”¨æˆ· {update.effective_user.id} æµ‹è¯•äº†æœåŠ¡å•† {provider_id}")

    elif operation == "stats":
        # æŸ¥çœ‹ä½¿ç”¨ç»Ÿè®¡: /aiconfig stats
        await show_ai_stats(update, context)

    elif operation == "timeout":
        # è®¾ç½®å¯¹è¯è¶…æ—¶æ—¶é—´: /aiconfig timeout <å°æ—¶æ•°>
        if len(context.args) < 2:
            await update.message.reply_text(
                "ç”¨æ³•: `/aiconfig timeout <å°æ—¶æ•°>`\n"
                "å½“å‰è¶…æ—¶æ—¶é—´: " +
                str(_state.get("conversation_timeout", 24 * 60 * 60) // 3600) +
                " å°æ—¶",
                parse_mode="MARKDOWN")
            return

        try:
            hours = float(context.args[1])
            if hours <= 0:
                await update.message.reply_text("è¶…æ—¶æ—¶é—´å¿…é¡»å¤§äº 0 å°æ—¶")
                return

            # æ›´æ–°è¶…æ—¶æ—¶é—´ (è½¬æ¢ä¸ºç§’)
            _state["conversation_timeout"] = int(hours * 3600)

            # ä¿å­˜é…ç½®
            save_config()

            await update.message.reply_text(f"âœ… å·²å°†å¯¹è¯è¶…æ—¶æ—¶é—´è®¾ç½®ä¸º {hours} å°æ—¶")
            module_interface.logger.info(
                f"ç”¨æˆ· {update.effective_user.id} å°†å¯¹è¯è¶…æ—¶æ—¶é—´è®¾ç½®ä¸º {hours} å°æ—¶")
        except ValueError:
            await update.message.reply_text("å°æ—¶æ•°å¿…é¡»æ˜¯æœ‰æ•ˆçš„æ•°å­—")

    else:
        # æœªçŸ¥æ“ä½œ
        await update.message.reply_text(
            f"æœªçŸ¥æ“ä½œ: `{operation}`\n"
            "å¯ç”¨æ“ä½œ: provider, default, delete, new, test, stats, timeout",
            parse_mode="MARKDOWN")


async def show_ai_config(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """æ˜¾ç¤ºå½“å‰ AI é…ç½®"""
    global _state

    # æ„å»ºé…ç½®ä¿¡æ¯
    config_text = "ğŸ¤– *AI é…ç½®é¢æ¿*\n\n"

    # é»˜è®¤æœåŠ¡å•†
    default_provider = _state["default_provider"]
    if default_provider and default_provider in _state["providers"]:
        provider_name = _state["providers"][default_provider].get(
            "name", default_provider)
        config_text += f"*å½“å‰é»˜è®¤æœåŠ¡å•†:* `{TextUtils.escape_markdown(default_provider)}` ({TextUtils.escape_markdown(provider_name)})\n\n"
    else:
        config_text += f"*å½“å‰é»˜è®¤æœåŠ¡å•†:* _æœªè®¾ç½®_\n\n"

    # å¯¹è¯è¶…æ—¶è®¾ç½®
    timeout_hours = _state.get("conversation_timeout", 24 * 60 * 60) // 3600
    config_text += f"*å¯¹è¯è¶…æ—¶æ—¶é—´:* `{timeout_hours}` å°æ—¶\n\n"

    # æœåŠ¡å•†åˆ—è¡¨
    config_text += "*å·²é…ç½®çš„æœåŠ¡å•†:*\n"

    if not _state["providers"]:
        config_text += "_æš‚æ— æœåŠ¡å•†é…ç½®ï¼Œè¯·ä½¿ç”¨_ `/aiconfig new` _åˆ›å»ºæœåŠ¡å•†_\n"
    else:
        # æ£€æŸ¥æ˜¯å¦æœ‰å®Œå…¨é…ç½®çš„æœåŠ¡å•†ï¼ˆæœ‰ API å¯†é’¥çš„ï¼‰
        configured_providers = [
            p for p, data in _state["providers"].items() if data.get("api_key")
        ]

        if not configured_providers:
            config_text += "_å·²åˆ›å»ºæœåŠ¡å•†ï¼Œä½†å°šæœªé…ç½® API å¯†é’¥ã€‚è¯·ä½¿ç”¨_ `/aiconfig provider <ID> api_key YOUR_KEY` _é…ç½®_\n\n"

        # æ˜¾ç¤ºæ‰€æœ‰æœåŠ¡å•†
        for provider_id, provider in _state["providers"].items():
            # æ ‡è®°é»˜è®¤æœåŠ¡å•†å’Œé…ç½®çŠ¶æ€
            is_default = "âœ… " if provider_id == default_provider else ""
            is_configured = "ğŸ”‘ " if provider.get("api_key") else "âš ï¸ "

            config_text += f"\n{is_default}{is_configured}*{TextUtils.escape_markdown(provider_id)}*\n"
            config_text += f"  ğŸ“ åç§°: `{TextUtils.escape_markdown(provider.get('name', provider_id))}`\n"
            config_text += f"  ğŸ¤– æ¨¡å‹: `{TextUtils.escape_markdown(provider.get('model', 'æœªè®¾ç½®'))}`\n"

            # API URL (å¯èƒ½å¾ˆé•¿ï¼Œæˆªæ–­æ˜¾ç¤º)
            api_url = provider.get('api_url', 'æœªè®¾ç½®')
            if len(api_url) > 30:
                api_url = api_url[:27] + "..."
            config_text += f"  ğŸ”— API URL: `{TextUtils.escape_markdown(api_url)}`\n"

            # API Key (éšè—æ˜¾ç¤º)
            api_key = provider.get('api_key', '')
            if api_key:
                masked_key = f"{api_key[:4]}...{api_key[-4:]}" if len(
                    api_key) > 8 else "****"
                config_text += f"  ğŸ”‘ API Key: `{TextUtils.escape_markdown(masked_key)}`\n"
            else:
                config_text += "  ğŸ”‘ API Key: `æœªè®¾ç½®` âš ï¸\n"

            config_text += f"  ğŸŒ¡ï¸ æ¸©åº¦: `{provider.get('temperature', 0.7)}`\n"

            # ç³»ç»Ÿæç¤º (å¯èƒ½å¾ˆé•¿ï¼Œæˆªæ–­æ˜¾ç¤º)
            system_prompt = provider.get('system_prompt', 'æœªè®¾ç½®')
            if len(system_prompt) > 30:
                system_prompt = system_prompt[:27] + "..."
            config_text += f"  ğŸ’¬ ç³»ç»Ÿæç¤º: `{TextUtils.escape_markdown(system_prompt)}`\n"

            config_text += f"  ğŸ“‹ è¯·æ±‚æ ¼å¼: `{TextUtils.escape_markdown(provider.get('request_format', 'openai'))}`\n"

    # æ·»åŠ ä½¿ç”¨è¯´æ˜
    config_text += "\n*ğŸ“š é…ç½®å‘½ä»¤:*\n"
    config_text += "â€¢ `/aiconfig provider <ID> <å‚æ•°> <å€¼>` - é…ç½®æœåŠ¡å•†å‚æ•°\n"
    config_text += "â€¢ `/aiconfig new <ID> [æ¨¡æ¿]` - åˆ›å»ºæ–°æœåŠ¡å•†\n"
    config_text += "â€¢ `/aiconfig default <ID>` - è®¾ç½®é»˜è®¤æœåŠ¡å•†\n"
    config_text += "â€¢ `/aiconfig delete <ID>` - åˆ é™¤æœåŠ¡å•†\n"
    config_text += "â€¢ `/aiconfig test <ID>` - æµ‹è¯•æœåŠ¡å•†\n"
    config_text += "â€¢ `/aiconfig stats` - æŸ¥çœ‹ä½¿ç”¨ç»Ÿè®¡\n"
    config_text += "â€¢ `/aiconfig timeout <å°æ—¶æ•°>` - è®¾ç½®å¯¹è¯è¶…æ—¶æ—¶é—´\n"

    try:
        await update.message.reply_text(config_text, parse_mode="MARKDOWN")
    except Exception as e:
        # å¦‚æœå‘é€å¤±è´¥ï¼ˆå¯èƒ½æ˜¯ Markdown æ ¼å¼é—®é¢˜ï¼‰ï¼Œå°è¯•å‘é€çº¯æ–‡æœ¬
        module_interface = context.bot_data[
            "bot_engine"].module_loader.get_module_interface(MODULE_NAME)
        module_interface.logger.error(f"å‘é€ AI é…ç½®ä¿¡æ¯å¤±è´¥: {e}")
        plain_text = TextUtils.markdown_to_plain(config_text)
        await update.message.reply_text(plain_text)


async def show_ai_stats(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """æ˜¾ç¤º AI ä½¿ç”¨ç»Ÿè®¡"""
    global _state

    stats = _state["usage_stats"]

    stats_text = "ğŸ“Š *AI ä½¿ç”¨ç»Ÿè®¡*\n\n"

    # æ€»è¯·æ±‚æ•°
    stats_text += f"*æ€»è¯·æ±‚æ•°:* `{stats.get('total_requests', 0)}`\n\n"

    # æŒ‰æœåŠ¡å•†ç»Ÿè®¡
    stats_text += "*æŒ‰æœåŠ¡å•†ç»Ÿè®¡:*\n"
    if not stats.get('requests_by_provider'):
        stats_text += "_æš‚æ— æ•°æ®_\n"
    else:
        for provider, count in stats.get('requests_by_provider', {}).items():
            provider_name = _state["providers"].get(provider, {}).get(
                "name",
                provider) if provider in _state["providers"] else provider
            stats_text += f"â€¢ `{TextUtils.escape_markdown(provider)}` ({TextUtils.escape_markdown(provider_name)}): `{count}`\n"

    # æŒ‰ç”¨æˆ·ç»Ÿè®¡ (ä»…æ˜¾ç¤ºå‰10ä½æ´»è·ƒç”¨æˆ·)
    stats_text += "\n*æŒ‰ç”¨æˆ·ç»Ÿè®¡ (å‰10ä½):*\n"
    if not stats.get('requests_by_user'):
        stats_text += "_æš‚æ— æ•°æ®_\n"
    else:
        # æŒ‰ä½¿ç”¨é‡æ’åº
        sorted_users = sorted(stats.get('requests_by_user', {}).items(),
                              key=lambda x: x[1],
                              reverse=True)[:10]

        for user_id, count in sorted_users:
            stats_text += f"â€¢ ç”¨æˆ· `{user_id}`: `{count}` æ¬¡è¯·æ±‚\n"

    try:
        await update.message.reply_text(stats_text, parse_mode="MARKDOWN")
    except Exception as e:
        module_interface = context.bot_data[
            "bot_engine"].module_loader.get_module_interface(MODULE_NAME)
        module_interface.logger.error(f"å‘é€ AI ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
        plain_text = TextUtils.markdown_to_plain(stats_text)
        await update.message.reply_text(plain_text)


@error_handler
@permission_check(admin_only="super_admin")
async def ai_whitelist_command(update: Update,
                               context: ContextTypes.DEFAULT_TYPE):
    """å¤„ç† /aiwhitelist å‘½ä»¤ - ç®¡ç† AI ç™½åå•"""
    global _state

    # è·å–æ¨¡å—æ¥å£
    module_interface = context.bot_data[
        "bot_engine"].module_loader.get_module_interface(MODULE_NAME)

    if not context.args:
        # æ˜¾ç¤ºå½“å‰ç™½åå•
        await show_ai_whitelist(update, context)
        return

    # è§£æå‘½ä»¤: /aiwhitelist <æ“ä½œ> <ç”¨æˆ·ID>
    operation = context.args[0].lower()

    if operation == "add":
        # æ·»åŠ ç”¨æˆ·åˆ°ç™½åå•
        if len(context.args) < 2 and not update.message.reply_to_message:
            await update.message.reply_text(
                "ç”¨æ³•: `/aiwhitelist add <ç”¨æˆ·ID>`\næˆ–å›å¤æŸäººçš„æ¶ˆæ¯æ·»åŠ ä»–ä»¬",
                parse_mode="MARKDOWN")
            return

        # æ£€æŸ¥æ˜¯å¦æ˜¯å›å¤æŸäººçš„æ¶ˆæ¯
        if update.message.reply_to_message and update.message.reply_to_message.from_user:
            user_id = update.message.reply_to_message.from_user.id
            username = update.message.reply_to_message.from_user.username or "æœªçŸ¥ç”¨æˆ·å"
            full_name = update.message.reply_to_message.from_user.full_name or "æœªçŸ¥å§“å"
        else:
            # ä»å‚æ•°è·å–ç”¨æˆ· ID
            try:
                user_id = int(context.args[1])
                username = "æœªçŸ¥ç”¨æˆ·å"
                full_name = "æœªçŸ¥å§“å"
            except ValueError:
                await update.message.reply_text("ç”¨æˆ· ID å¿…é¡»æ˜¯æ•°å­—")
                return

        # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å·²åœ¨ç™½åå•ä¸­
        if user_id in _state["whitelist"]:
            escaped_username = TextUtils.escape_markdown(username)
            await update.message.reply_text(
                f"ç”¨æˆ· `{user_id}` (@{escaped_username}) å·²åœ¨ç™½åå•ä¸­",
                parse_mode="MARKDOWN")
            return

        # æ·»åŠ åˆ°ç™½åå•
        _state["whitelist"].append(user_id)

        # ä¿å­˜é…ç½®
        save_config()

        # ä½¿ç”¨ TextUtils è½¬ä¹‰ç”¨æˆ·åå’Œå…¨åä¸­çš„ç‰¹æ®Šå­—ç¬¦
        escaped_username = TextUtils.escape_markdown(username)
        escaped_full_name = TextUtils.escape_markdown(full_name)

        await update.message.reply_text(
            f"âœ… å·²å°†ç”¨æˆ· `{user_id}` (@{escaped_username}, {escaped_full_name}) æ·»åŠ åˆ°ç™½åå•",
            parse_mode="MARKDOWN")
        module_interface.logger.info(
            f"ç”¨æˆ· {update.effective_user.id} å°†ç”¨æˆ· {user_id} æ·»åŠ åˆ° AI ç™½åå•")

    elif operation == "remove":
        # ä»ç™½åå•ä¸­ç§»é™¤ç”¨æˆ·
        if len(context.args) < 2:
            await update.message.reply_text("ç”¨æ³•: `/aiwhitelist remove <ç”¨æˆ·ID>`",
                                            parse_mode="MARKDOWN")
            return

        try:
            user_id = int(context.args[1])

            # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦åœ¨ç™½åå•ä¸­
            if user_id not in _state["whitelist"]:
                await update.message.reply_text(f"ç”¨æˆ· `{user_id}` ä¸åœ¨ç™½åå•ä¸­",
                                                parse_mode="MARKDOWN")
                return

            # ä»ç™½åå•ä¸­ç§»é™¤
            _state["whitelist"].remove(user_id)

            # ä¿å­˜é…ç½®
            save_config()

            await update.message.reply_text(f"âœ… å·²å°†ç”¨æˆ· `{user_id}` ä»ç™½åå•ä¸­ç§»é™¤",
                                            parse_mode="MARKDOWN")
            module_interface.logger.info(
                f"ç”¨æˆ· {update.effective_user.id} å°†ç”¨æˆ· {user_id} ä» AI ç™½åå•ä¸­ç§»é™¤")
        except ValueError:
            await update.message.reply_text("ç”¨æˆ· ID å¿…é¡»æ˜¯æ•°å­—")

    elif operation == "clear":
        # æ¸…ç©ºç™½åå•
        _state["whitelist"] = []

        # ä¿å­˜é…ç½®
        save_config()

        await update.message.reply_text("âœ… å·²æ¸…ç©º AI ç™½åå•")
        module_interface.logger.info(
            f"ç”¨æˆ· {update.effective_user.id} æ¸…ç©ºäº† AI ç™½åå•")

    else:
        # æœªçŸ¥æ“ä½œ
        await update.message.reply_text(
            f"æœªçŸ¥æ“ä½œ: `{operation}`\n"
            "å¯ç”¨æ“ä½œ: add, remove, clear",
            parse_mode="MARKDOWN")


async def show_ai_whitelist(update: Update,
                            context: ContextTypes.DEFAULT_TYPE):
    """æ˜¾ç¤ºå½“å‰ AI ç™½åå•"""
    global _state

    whitelist_text = "ğŸ‘¥ *AI ç™½åå•ç”¨æˆ·*\n\n"

    if not _state["whitelist"]:
        whitelist_text += "_ç™½åå•ä¸ºç©º_\n"
    else:
        for i, user_id in enumerate(_state["whitelist"], 1):
            whitelist_text += f"{i}. `{user_id}`\n"

    whitelist_text += "\n*ğŸ“š ç™½åå•ç®¡ç†å‘½ä»¤:*\n"
    whitelist_text += "â€¢ `/aiwhitelist add <ç”¨æˆ·ID>` - æ·»åŠ ç”¨æˆ·åˆ°ç™½åå•\n"
    whitelist_text += "â€¢ `/aiwhitelist remove <ç”¨æˆ·ID>` - ä»ç™½åå•ä¸­ç§»é™¤ç”¨æˆ·\n"
    whitelist_text += "â€¢ `/aiwhitelist clear` - æ¸…ç©ºç™½åå•\n"
    whitelist_text += "\nğŸ’¡ æç¤ºï¼šå›å¤ç”¨æˆ·æ¶ˆæ¯å¹¶ä½¿ç”¨ `/aiwhitelist add` å¯å¿«é€Ÿæ·»åŠ è¯¥ç”¨æˆ·\n"

    try:
        await update.message.reply_text(whitelist_text, parse_mode="MARKDOWN")
    except Exception as e:
        # å¦‚æœå‘é€å¤±è´¥ï¼Œå°è¯•å‘é€çº¯æ–‡æœ¬
        module_interface = context.bot_data[
            "bot_engine"].module_loader.get_module_interface(MODULE_NAME)
        module_interface.logger.error(f"å‘é€ AI ç™½åå•ä¿¡æ¯å¤±è´¥: {e}")
        plain_text = TextUtils.markdown_to_plain(whitelist_text)
        await update.message.reply_text(plain_text)


@error_handler
@module_check
async def ai_clear_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """å¤„ç† /aiclear å‘½ä»¤ - æ¸…é™¤å¯¹è¯ä¸Šä¸‹æ–‡"""
    user_id = update.effective_user.id

    # è·å–æ¨¡å—æ¥å£
    module_interface = context.bot_data[
        "bot_engine"].module_loader.get_module_interface(MODULE_NAME)

    # æ£€æŸ¥æƒé™
    if not can_use_ai(user_id, update.effective_chat.type, context):
        await update.message.reply_text("âš ï¸ æ‚¨æ²¡æœ‰ä½¿ç”¨ AI åŠŸèƒ½çš„æƒé™\nè¯·è”ç³»ç®¡ç†å‘˜å°†æ‚¨æ·»åŠ åˆ°ç™½åå•")
        module_interface.logger.warning(f"ç”¨æˆ· {user_id} å°è¯•ä½¿ç”¨ AI åŠŸèƒ½ä½†æ²¡æœ‰æƒé™")
        return

    # æ¸…é™¤ä¸Šä¸‹æ–‡
    if clear_user_context(user_id):
        await update.message.reply_text("âœ… å·²æ¸…é™¤æ‚¨çš„å¯¹è¯å†å²")
        module_interface.logger.info(f"ç”¨æˆ· {user_id} æ¸…é™¤äº†å¯¹è¯å†å²")
    else:
        await update.message.reply_text("æ‚¨è¿˜æ²¡æœ‰ä»»ä½•å¯¹è¯å†å²")


@error_handler
@module_check
async def ai_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """å¤„ç† /ai å‘½ä»¤ - å‘ AI å‘é€æ¶ˆæ¯"""
    user_id = update.effective_user.id

    # è·å–æ¨¡å—æ¥å£
    module_interface = context.bot_data[
        "bot_engine"].module_loader.get_module_interface(MODULE_NAME)

    # æ£€æŸ¥æƒé™
    if not can_use_ai(user_id, update.effective_chat.type, context):
        await update.message.reply_text("âš ï¸ æ‚¨æ²¡æœ‰ä½¿ç”¨ AI åŠŸèƒ½çš„æƒé™\nè¯·è”ç³»ç®¡ç†å‘˜å°†æ‚¨æ·»åŠ åˆ°ç™½åå•")
        module_interface.logger.warning(f"ç”¨æˆ· {user_id} å°è¯•ä½¿ç”¨ AI åŠŸèƒ½ä½†æ²¡æœ‰æƒé™")
        return

    # æ£€æŸ¥æ˜¯å¦æœ‰æ¶ˆæ¯å†…å®¹
    if not context.args:
        await update.message.reply_text(
            "è¯·è¾“å…¥è¦å‘é€ç»™ AI çš„æ¶ˆæ¯\n"
            "ä¾‹å¦‚: `/ai ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±`\n\n"
            "ğŸ”„ ä½¿ç”¨ `/aiclear` å¯æ¸…é™¤å¯¹è¯å†å²",
            parse_mode="MARKDOWN")
        return

    # è·å–æ¶ˆæ¯å†…å®¹
    message_text = " ".join(context.args)

    # æ£€æŸ¥æ¶ˆæ¯é•¿åº¦
    if len(message_text) > MAX_MESSAGE_LENGTH:
        await update.message.reply_text(
            f"âš ï¸ æ¶ˆæ¯å¤ªé•¿ï¼Œè¯·å°†é•¿åº¦æ§åˆ¶åœ¨ {MAX_MESSAGE_LENGTH} å­—ç¬¦ä»¥å†…")
        return

    # æ£€æŸ¥é»˜è®¤æœåŠ¡å•†
    provider_id = _state["default_provider"]
    if not provider_id or provider_id not in _state["providers"]:
        await update.message.reply_text("âš ï¸ æœªé…ç½®é»˜è®¤ AI æœåŠ¡å•†ï¼Œè¯·è”ç³»ç®¡ç†å‘˜")
        module_interface.logger.warning(f"ç”¨æˆ· {user_id} å°è¯•ä½¿ç”¨ AI ä½†æœªé…ç½®é»˜è®¤æœåŠ¡å•†")
        return

    # å‘é€"æ­£åœ¨æ€è€ƒ"æ¶ˆæ¯
    thinking_message = await update.message.reply_text("ğŸ¤” æ­£åœ¨æ€è€ƒä¸­...")

    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°ä¸Šä¸‹æ–‡
    add_message_to_context(user_id, "user", message_text)

    # å‡†å¤‡ API è¯·æ±‚
    messages = format_context_for_api(provider_id, user_id)

    # åˆ›å»ºæµå¼æ›´æ–°å›è°ƒå‡½æ•°
    async def update_message_callback(text):
        try:
            # ç¡®ä¿æ–‡æœ¬ä¸ä¸ºç©º
            if not text.strip():
                return

            # å­˜å‚¨ä¸Šä¸€æ¬¡æ›´æ–°çš„æ–‡æœ¬ï¼Œé¿å…é‡å¤æ›´æ–°
            if not hasattr(update_message_callback, 'last_text'):
                update_message_callback.last_text = ""

            # å¦‚æœæ–‡æœ¬ä¸ä¸Šæ¬¡ç›¸åŒï¼Œä¸æ›´æ–°
            if text == update_message_callback.last_text:
                return

            # æµå¼æ›´æ–°æ—¶ä½¿ç”¨çº¯æ–‡æœ¬
            if len(text) <= MAX_MESSAGE_LENGTH:
                await thinking_message.edit_text(text)
            else:
                # å¦‚æœæ¶ˆæ¯è¶…é•¿ï¼Œåªæ›´æ–°æœ€åéƒ¨åˆ†
                await thinking_message.edit_text(text[-MAX_MESSAGE_LENGTH:])

            # æ›´æ–°ä¸Šæ¬¡æ–‡æœ¬
            update_message_callback.last_text = text
        except Exception as e:
            # å¿½ç•¥"æ¶ˆæ¯æœªä¿®æ”¹"é”™è¯¯
            if "Message is not modified" not in str(e):
                module_interface.logger.error(f"æ›´æ–°æ¶ˆæ¯å¤±è´¥: {e}")

    # è°ƒç”¨æµå¼ AI API
    response = await call_ai_api_stream(provider_id, messages,
                                        module_interface,
                                        update_message_callback)

    # æ·»åŠ  AI å›å¤åˆ°ä¸Šä¸‹æ–‡
    add_message_to_context(user_id, "assistant", response)

    # å¤„ç†æœ€ç»ˆå“åº” - ä½¿ç”¨ HTML æ ¼å¼
    try:
        # åˆ é™¤"æ€è€ƒä¸­"æ¶ˆæ¯
        await thinking_message.delete()

        # ä½¿ç”¨ HTML æ ¼å¼å‘é€å“åº”
        await TextUtils.send_long_message_html(update, response,
                                               module_interface)
    except Exception as e:
        module_interface.logger.error(f"å¤„ç†æœ€ç»ˆå“åº”å¤±è´¥: {e}")
        # ç›´æ¥å‘é€çº¯æ–‡æœ¬
        try:
            # åˆ†æ®µå‘é€çº¯æ–‡æœ¬
            MAX_PLAIN_LENGTH = 4000

            if len(response) <= MAX_PLAIN_LENGTH:
                await update.message.reply_text(response)
            else:
                # åˆ†æ®µå‘é€
                parts = []
                for i in range(0, len(response), MAX_PLAIN_LENGTH):
                    parts.append(response[i:i + MAX_PLAIN_LENGTH])

                module_interface.logger.info(f"æ¶ˆæ¯è¿‡é•¿ï¼Œå°†åˆ†ä¸º {len(parts)} æ®µçº¯æ–‡æœ¬å‘é€")

                # å‘é€ç¬¬ä¸€æ®µ
                first_message = await update.message.reply_text(parts[0])

                # å‘é€å‰©ä½™æ®µè½
                for part in parts[1:]:
                    await first_message.reply_text(part)

        except Exception as inner_e:
            module_interface.logger.error(f"å‘é€çº¯æ–‡æœ¬ä¹Ÿå¤±è´¥: {inner_e}")
            # æœ€åçš„å›é€€ï¼šå‘é€ä¸€ä¸ªç®€å•çš„é”™è¯¯æ¶ˆæ¯
            await update.message.reply_text("ç”Ÿæˆå›å¤æ—¶å‡ºé”™ï¼Œè¯·é‡è¯•")

    module_interface.logger.info(
        f"ç”¨æˆ· {user_id} ä½¿ç”¨ {provider_id} æœåŠ¡å•†è·å¾—äº† AI æµå¼å›å¤")


@error_handler
async def handle_private_message(update: Update,
                                 context: ContextTypes.DEFAULT_TYPE):
    """å¤„ç†ç§èŠæ¶ˆæ¯ï¼Œç›´æ¥å›å¤ AI å›ç­”"""
    # å¦‚æœæ˜¯å‘½ä»¤ï¼Œå¿½ç•¥
    if update.message.text.startswith('/'):
        return

    # æ£€æŸ¥æ¨¡å—æ˜¯å¦å¯ç”¨
    bot_engine = context.bot_data.get("bot_engine")
    config_manager = context.bot_data.get("config_manager")
    chat_id = update.effective_chat.id

    # æ‰‹åŠ¨æ£€æŸ¥æ¨¡å—æ˜¯å¦ä¸ºå½“å‰èŠå¤©å¯ç”¨
    if not config_manager.is_module_enabled_for_chat(MODULE_NAME, chat_id):
        return

    user_id = update.effective_user.id

    # è·å–æ¨¡å—æ¥å£
    module_interface = bot_engine.module_loader.get_module_interface(
        MODULE_NAME)

    # æ£€æŸ¥æƒé™
    if not can_use_ai(user_id, "private", context):
        # ä¸å›å¤éç™½åå•ç”¨æˆ·
        return

    # è·å–æ¶ˆæ¯å†…å®¹
    message_text = update.message.text

    # æ£€æŸ¥æ¶ˆæ¯é•¿åº¦
    if len(message_text) > MAX_MESSAGE_LENGTH:
        await update.message.reply_text(
            f"âš ï¸ æ¶ˆæ¯å¤ªé•¿ï¼Œè¯·å°†é•¿åº¦æ§åˆ¶åœ¨ {MAX_MESSAGE_LENGTH} å­—ç¬¦ä»¥å†…")
        return

    # æ£€æŸ¥é»˜è®¤æœåŠ¡å•†
    provider_id = _state["default_provider"]
    if not provider_id or provider_id not in _state["providers"]:
        await update.message.reply_text("âš ï¸ æœªé…ç½®é»˜è®¤ AI æœåŠ¡å•†ï¼Œè¯·è”ç³»ç®¡ç†å‘˜")
        module_interface.logger.warning(f"ç”¨æˆ· {user_id} å°è¯•ä½¿ç”¨ AI ä½†æœªé…ç½®é»˜è®¤æœåŠ¡å•†")
        return

    # å‘é€"æ­£åœ¨æ€è€ƒ"æ¶ˆæ¯
    thinking_message = await update.message.reply_text("ğŸ¤” æ­£åœ¨æ€è€ƒä¸­...")

    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°ä¸Šä¸‹æ–‡
    add_message_to_context(user_id, "user", message_text)

    # å‡†å¤‡ API è¯·æ±‚
    messages = format_context_for_api(provider_id, user_id)

    # åˆ›å»ºæµå¼æ›´æ–°å›è°ƒå‡½æ•°
    async def update_message_callback(text):
        try:
            # ç¡®ä¿æ–‡æœ¬ä¸ä¸ºç©º
            if not text.strip():
                return

            # å­˜å‚¨ä¸Šä¸€æ¬¡æ›´æ–°çš„æ–‡æœ¬ï¼Œé¿å…é‡å¤æ›´æ–°
            if not hasattr(update_message_callback, 'last_text'):
                update_message_callback.last_text = ""

            # å¦‚æœæ–‡æœ¬ä¸ä¸Šæ¬¡ç›¸åŒï¼Œä¸æ›´æ–°
            if text == update_message_callback.last_text:
                return

            # æµå¼æ›´æ–°æ—¶ä½¿ç”¨çº¯æ–‡æœ¬
            if len(text) <= MAX_MESSAGE_LENGTH:
                await thinking_message.edit_text(text)
            else:
                # å¦‚æœæ¶ˆæ¯è¶…é•¿ï¼Œåªæ›´æ–°æœ€åéƒ¨åˆ†
                await thinking_message.edit_text(text[-MAX_MESSAGE_LENGTH:])

            # æ›´æ–°ä¸Šæ¬¡æ–‡æœ¬
            update_message_callback.last_text = text
        except Exception as e:
            # å¿½ç•¥"æ¶ˆæ¯æœªä¿®æ”¹"é”™è¯¯
            if "Message is not modified" not in str(e):
                module_interface.logger.error(f"æ›´æ–°æ¶ˆæ¯å¤±è´¥: {e}")

    # è°ƒç”¨æµå¼ AI API
    response = await call_ai_api_stream(provider_id, messages,
                                        module_interface,
                                        update_message_callback)

    # æ·»åŠ  AI å›å¤åˆ°ä¸Šä¸‹æ–‡
    add_message_to_context(user_id, "assistant", response)

    # å¤„ç†æœ€ç»ˆå“åº” - ä½¿ç”¨ HTML æ ¼å¼
    try:
        # åˆ é™¤"æ€è€ƒä¸­"æ¶ˆæ¯
        await thinking_message.delete()

        # ä½¿ç”¨ HTML æ ¼å¼å‘é€å“åº”
        await TextUtils.send_long_message_html(update, response,
                                               module_interface)
    except Exception as e:
        module_interface.logger.error(f"å¤„ç†æœ€ç»ˆå“åº”å¤±è´¥: {e}")
        # ç›´æ¥å‘é€çº¯æ–‡æœ¬
        try:
            # åˆ†æ®µå‘é€çº¯æ–‡æœ¬
            MAX_PLAIN_LENGTH = 4000

            if len(response) <= MAX_PLAIN_LENGTH:
                await update.message.reply_text(response)
            else:
                # åˆ†æ®µå‘é€
                parts = []
                for i in range(0, len(response), MAX_PLAIN_LENGTH):
                    parts.append(response[i:i + MAX_PLAIN_LENGTH])

                module_interface.logger.info(f"æ¶ˆæ¯è¿‡é•¿ï¼Œå°†åˆ†ä¸º {len(parts)} æ®µçº¯æ–‡æœ¬å‘é€")

                # å‘é€ç¬¬ä¸€æ®µ
                first_message = await update.message.reply_text(parts[0])

                # å‘é€å‰©ä½™æ®µè½
                for part in parts[1:]:
                    await first_message.reply_text(part)

        except Exception as inner_e:
            module_interface.logger.error(f"å‘é€çº¯æ–‡æœ¬ä¹Ÿå¤±è´¥: {inner_e}")
            # æœ€åçš„å›é€€ï¼šå‘é€ä¸€ä¸ªç®€å•çš„é”™è¯¯æ¶ˆæ¯
            await update.message.reply_text("ç”Ÿæˆå›å¤æ—¶å‡ºé”™ï¼Œè¯·é‡è¯•")

    module_interface.logger.info(f"ç”¨æˆ· {user_id} åœ¨ç§èŠä¸­è·å¾—äº† AI æµå¼å›å¤")


# è·å–æ¨¡å—çŠ¶æ€çš„æ–¹æ³•ï¼ˆç”¨äºçƒ­æ›´æ–°ï¼‰
def get_state(module_interface):
    """è·å–æ¨¡å—çŠ¶æ€ï¼ˆç”¨äºçƒ­æ›´æ–°ï¼‰"""
    module_interface.logger.debug("æ­£åœ¨è·å– AI æ¨¡å—çŠ¶æ€ç”¨äºçƒ­æ›´æ–°")
    return _state


# è®¾ç½®æ¨¡å—çŠ¶æ€çš„æ–¹æ³•ï¼ˆç”¨äºçƒ­æ›´æ–°ï¼‰
def set_state(module_interface, state):
    """è®¾ç½®æ¨¡å—çŠ¶æ€ï¼ˆç”¨äºçƒ­æ›´æ–°ï¼‰"""
    global _state

    # ç¡®ä¿çŠ¶æ€ä¸­åŒ…å«æ‰€æœ‰å¿…è¦çš„å­—æ®µ
    state.setdefault("providers", {})
    state.setdefault("whitelist", [])
    state.setdefault("conversations", {})
    state.setdefault("default_provider", None)
    state.setdefault("last_save_time", time.time())
    state.setdefault("usage_stats", {
        "total_requests": 0,
        "requests_by_provider": {},
        "requests_by_user": {}
    })
    state.setdefault("conversation_timeout", 24 * 60 * 60)  # é»˜è®¤ 24 å°æ—¶

    _state = state
    module_interface.logger.debug("å·²æ¢å¤ AI æ¨¡å—çŠ¶æ€")


def setup(module_interface):
    """æ¨¡å—åˆå§‹åŒ–"""
    global _state, re

    # ç¡®ä¿å¯¼å…¥äº† re æ¨¡å—
    if 're' not in globals():
        import re

    # åˆå§‹åŒ–çŠ¶æ€
    _state = {
        "providers": {},
        "whitelist": [],
        "conversations": {},
        "default_provider": None,
        "last_save_time": time.time(),
        "usage_stats": {
            "total_requests": 0,
            "requests_by_provider": {},
            "requests_by_user": {}
        },
        "conversation_timeout": 24 * 60 * 60  # é»˜è®¤ 24 å°æ—¶
    }

    # ä»æŒä¹…åŒ–å­˜å‚¨åŠ è½½çŠ¶æ€
    saved_state = module_interface.load_state(default={})
    if saved_state:
        set_state(module_interface, saved_state)
    else:
        # å¦‚æœæ²¡æœ‰ä¿å­˜çš„çŠ¶æ€ï¼ŒåŠ è½½é…ç½®æ–‡ä»¶
        load_config()
        load_contexts()

    # æ³¨å†Œå‘½ä»¤
    module_interface.register_command("aiconfig",
                                      ai_config_command,
                                      admin_only="super_admin")
    module_interface.register_command("aiwhitelist",
                                      ai_whitelist_command,
                                      admin_only="super_admin")
    module_interface.register_command("aiclear", ai_clear_command)
    module_interface.register_command("ai", ai_command)

    # æ³¨å†Œç§èŠæ¶ˆæ¯å¤„ç†å™¨
    private_handler = MessageHandler(
        filters.TEXT & filters.ChatType.PRIVATE & ~filters.COMMAND,
        handle_private_message)
    module_interface.register_handler(private_handler)

    # è®¾ç½®å®šæœŸä»»åŠ¡
    async def _periodic_tasks():
        while True:
            try:
                # æ¯å°æ—¶æ£€æŸ¥ä¸€æ¬¡è¿‡æœŸå¯¹è¯
                await asyncio.sleep(3600)
                expired_count = cleanup_expired_conversations()
                if expired_count > 0:
                    module_interface.logger.info(f"å·²æ¸…ç† {expired_count} ä¸ªè¿‡æœŸå¯¹è¯")

                # ä¿å­˜çŠ¶æ€
                module_interface.save_state(_state)
                module_interface.logger.debug("å·²å®šæœŸä¿å­˜ AI æ¨¡å—çŠ¶æ€")
            except Exception as e:
                module_interface.logger.error(f"å®šæœŸä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")

    # å¯åŠ¨å®šæœŸä»»åŠ¡
    module_interface.periodic_task = asyncio.create_task(_periodic_tasks())

    module_interface.logger.info(f"æ¨¡å— {MODULE_NAME} v{MODULE_VERSION} å·²åˆå§‹åŒ–")


def cleanup(module_interface):
    """æ¨¡å—æ¸…ç†"""
    # å–æ¶ˆå®šæœŸä»»åŠ¡
    if hasattr(module_interface,
               'periodic_task') and module_interface.periodic_task:
        module_interface.periodic_task.cancel()

    # ä¿å­˜çŠ¶æ€
    module_interface.save_state(_state)

    module_interface.logger.info(f"æ¨¡å— {MODULE_NAME} å·²æ¸…ç†")
