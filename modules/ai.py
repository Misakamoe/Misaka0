# modules/ai.py - AI èŠå¤©åŠ©æ‰‹

import os
import json
import time
import asyncio
import aiohttp
import base64
import telegram
from typing import Dict, List, Optional, Any, Tuple, Callable, Union
from utils.formatter import TextFormatter
from telegram import Update, File
from telegram.ext import ContextTypes, MessageHandler, filters

# æ¨¡å—å…ƒæ•°æ®
MODULE_NAME = "ai"
MODULE_VERSION = "2.0.0"
MODULE_DESCRIPTION = "æ”¯æŒå¤šç§ AI çš„èŠå¤©åŠ©æ‰‹"
MODULE_DEPENDENCIES = []
MODULE_COMMANDS = ["ai", "aiconfig", "aiclear", "aiwhitelist"]

# æ¨¡å—æ¥å£å¼•ç”¨
_interface = None

# é…ç½®æ–‡ä»¶è·¯å¾„
CONFIG_FILE = "config/ai_config.json"
CONTEXT_FILE = "data/ai_contexts.json"

# å¸¸é‡å®šä¹‰
MAX_CONTEXT_LENGTH = 15  # ä¸Šä¸‹æ–‡æœ€å¤§æ¶ˆæ¯å¯¹æ•°
REQUEST_TIMEOUT = 60  # API è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
MAX_MESSAGE_LENGTH = 4000  # Telegram æœ€å¤§æ¶ˆæ¯é•¿åº¦
MIN_UPDATE_INTERVAL = 1.5  # æœ€å°æµå¼æ›´æ–°é—´éš”ï¼ˆç§’ï¼‰
MAX_CONCURRENT_REQUESTS = 5  # æœ€å¤§å¹¶å‘è¯·æ±‚æ•°

# æœåŠ¡å•†æ¨¡æ¿
PROVIDER_TEMPLATES = {
    "openai": {
        "name": "OpenAI",
        "api_url": "https://api.openai.com/v1/chat/completions",
        "api_key": "",
        "model": "gpt-4.1-nano",
        "temperature": 0.7,
        "system_prompt": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ã€‚",
        "request_format": "openai",
        "supports_image": True
    },
    "gemini": {
        "name": "Gemini",
        "api_url":
        "https://generativelanguage.googleapis.com/v1/models/{model}:generateContent",
        "api_key": "",
        "model": "gemini-2.0-flash",
        "temperature": 0.7,
        "system_prompt": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ã€‚",
        "request_format": "gemini",
        "supports_image": True
    },
    "anthropic": {
        "name": "Claude",
        "api_url": "https://api.anthropic.com/v1/messages",
        "api_key": "",
        "model": "claude-3-5-sonnet-latest",
        "temperature": 0.7,
        "system_prompt": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ã€‚",
        "request_format": "anthropic",
        "supports_image": True
    },
    "custom": {
        "name": "Custom",
        "api_url": "",
        "api_key": "",
        "model": "",
        "temperature": 0.7,
        "system_prompt": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ã€‚",
        "request_format": "openai",
        "supports_image": True
    }
}

# æ¨¡å—çŠ¶æ€
_state = {
    "providers": {},  # æœåŠ¡å•†é…ç½®
    "whitelist": [],  # ç™½åå•ç”¨æˆ· ID
    "conversations": {},  # ç”¨æˆ·å¯¹è¯ä¸Šä¸‹æ–‡
    "default_provider": None,  # é»˜è®¤æœåŠ¡å•†
    "usage_stats": {  # ä½¿ç”¨ç»Ÿè®¡
        "total_requests": 0,
        "requests_by_provider": {},
        "requests_by_user": {}
    },
    "conversation_timeout": 24 * 60 * 60,  # é»˜è®¤ 24 å°æ—¶è¶…æ—¶
    "concurrent_requests": 0,  # å½“å‰å¹¶å‘è¯·æ±‚æ•°
    "request_lock": None  # è¯·æ±‚é”ï¼ˆè¿è¡Œæ—¶åˆå§‹åŒ–ï¼‰
}


class AIServiceProvider:
    """AI æœåŠ¡æä¾›å•†æŠ½è±¡åŸºç±»"""

    @staticmethod
    async def format_request(provider: Dict[str, Any],
                             messages: List[Dict[str, str]],
                             images: Optional[List[Dict[str, Any]]] = None,
                             stream: bool = False) -> Dict[str, Any]:
        """æ ¼å¼åŒ– API è¯·æ±‚
        
        Args:
            provider: æœåŠ¡å•†é…ç½®
            messages: æ¶ˆæ¯åˆ—è¡¨
            images: å›¾åƒåˆ—è¡¨ (å¯é€‰)
            stream: æ˜¯å¦ä½¿ç”¨æµå¼è¯·æ±‚
            
        Returns:
            Dict: æ ¼å¼åŒ–çš„è¯·æ±‚æ•°æ®
        """
        request_format = provider.get("request_format", "openai")

        if request_format == "openai":
            return OpenAIProvider.format_request(provider, messages, images,
                                                 stream)
        elif request_format == "gemini":
            return GeminiProvider.format_request(provider, messages, images,
                                                 stream)
        elif request_format == "anthropic":
            return AnthropicProvider.format_request(provider, messages, images,
                                                    stream)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„è¯·æ±‚æ ¼å¼: {request_format}")

    @staticmethod
    async def parse_response(provider: Dict[str, Any],
                             response_data: Dict[str, Any]) -> str:
        """è§£æ API å“åº”
        
        Args:
            provider: æœåŠ¡å•†é…ç½®
            response_data: API å“åº”æ•°æ®
            
        Returns:
            str: è§£æåçš„æ–‡æœ¬å“åº”
        """
        request_format = provider.get("request_format", "openai")

        if request_format == "openai":
            return OpenAIProvider.parse_response(response_data)
        elif request_format == "gemini":
            return GeminiProvider.parse_response(response_data)
        elif request_format == "anthropic":
            return AnthropicProvider.parse_response(response_data)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„å“åº”æ ¼å¼: {request_format}")

    @staticmethod
    async def prepare_api_request(
            provider: Dict[str, Any],
            request_data: Dict[str, Any]) -> Tuple[str, Dict[str, str]]:
        """å‡†å¤‡ API è¯·æ±‚ URL å’Œå¤´ä¿¡æ¯
        
        Args:
            provider: æœåŠ¡å•†é…ç½®
            request_data: è¯·æ±‚æ•°æ®
            
        Returns:
            Tuple[str, Dict[str, str]]: API URL å’Œè¯·æ±‚å¤´
        """
        request_format = provider.get("request_format", "openai")

        # å‡†å¤‡ API URL
        api_url = provider["api_url"]
        if "{model}" in api_url:
            api_url = api_url.replace("{model}", provider["model"])

        # å‡†å¤‡è¯·æ±‚å¤´
        headers = {"Content-Type": "application/json"}

        # ä¸åŒæœåŠ¡å•†çš„è®¤è¯æ–¹å¼
        if request_format == "openai":
            headers["Authorization"] = f"Bearer {provider['api_key']}"
        elif request_format == "gemini":
            # Gemini ä½¿ç”¨ URL å‚æ•°ä¼ é€’ API å¯†é’¥
            api_url = f"{api_url}?key={provider['api_key']}"
        elif request_format == "anthropic":
            headers["x-api-key"] = provider["api_key"]
            headers["anthropic-version"] = "2023-06-01"

        return api_url, headers


class OpenAIProvider:
    """OpenAI æœåŠ¡æä¾›å•†å®ç°"""

    @staticmethod
    def format_request(provider: Dict[str, Any],
                       messages: List[Dict[str, str]],
                       images: Optional[List[Dict[str, Any]]] = None,
                       stream: bool = False) -> Dict[str, Any]:
        """æ ¼å¼åŒ– OpenAI è¯·æ±‚"""
        # å¦‚æœæœ‰å›¾åƒä¸”æ¨¡å‹æ”¯æŒå›¾åƒ
        if images and provider.get("model", "").startswith(
            ("gpt-4-vision", "gpt-4o")):
            # æ„å»ºåŒ…å«å›¾åƒçš„æ¶ˆæ¯
            vision_messages = []

            for msg in messages:
                if msg["role"] == "user" and images:
                    # ä¸ºç”¨æˆ·æ¶ˆæ¯æ·»åŠ å›¾åƒ
                    content = [{"type": "text", "text": msg["content"]}]

                    # æ·»åŠ å›¾åƒ
                    for img in images:
                        content.append({
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{img['data']}",
                                "detail": "high"
                            }
                        })

                    vision_messages.append({
                        "role": msg["role"],
                        "content": content
                    })
                else:
                    # ä¿æŒå…¶ä»–æ¶ˆæ¯ä¸å˜
                    vision_messages.append(msg)

            return {
                "model": provider["model"],
                "messages": vision_messages,
                "temperature": provider["temperature"],
                "stream": stream,
                "max_tokens": 4096
            }
        else:
            # æ ‡å‡†æ–‡æœ¬è¯·æ±‚
            return {
                "model": provider["model"],
                "messages": messages,
                "temperature": provider["temperature"],
                "stream": stream,
                "max_tokens": 4096
            }

    @staticmethod
    def parse_response(response_data: Dict[str, Any]) -> str:
        """è§£æ OpenAI å“åº”"""
        try:
            return response_data["choices"][0]["message"]["content"]
        except (KeyError, IndexError) as e:
            _interface.logger.error(f"è§£æ OpenAI å“åº”å¤±è´¥: {e}")
            return None

    @staticmethod
    async def process_stream(line: bytes, callback: Callable[[str], None],
                             full_response: str) -> str:
        """å¤„ç† OpenAI æµå¼å“åº”"""
        if not line or line == b'data: [DONE]':
            return full_response

        try:
            # ç§»é™¤ "data: " å‰ç¼€å¹¶è§£æ JSON
            if line.startswith(b'data: '):
                json_data = json.loads(line[6:])

                if 'choices' in json_data and json_data['choices']:
                    delta = json_data['choices'][0].get('delta', {})
                    if 'content' in delta and delta['content']:
                        content = delta['content']
                        full_response += content

                        # åªæœ‰å½“æœ‰å®é™…å†…å®¹æ—¶æ‰è°ƒç”¨å›è°ƒ
                        if full_response.strip():
                            await callback(full_response)
        except Exception as e:
            _interface.logger.error(f"è§£æ OpenAI æµå¼å“åº”å¤±è´¥: {e}")

        return full_response


class GeminiProvider:
    """Google Gemini æœåŠ¡æä¾›å•†å®ç°"""

    @staticmethod
    def format_request(provider: Dict[str, Any],
                       messages: List[Dict[str, str]],
                       images: Optional[List[Dict[str, Any]]] = None,
                       stream: bool = False) -> Dict[str, Any]:
        """æ ¼å¼åŒ– Gemini è¯·æ±‚"""
        # è½¬æ¢æ¶ˆæ¯æ ¼å¼ä¸º Gemini æ ¼å¼
        gemini_messages = []

        for msg in messages:
            role = msg["role"]
            content = msg["content"]

            if role == "system":
                # ç³»ç»Ÿæ¶ˆæ¯ä½œä¸ºç”¨æˆ·æ¶ˆæ¯çš„å‰ç¼€
                if gemini_messages and gemini_messages[-1]["role"] == "user":
                    gemini_messages[-1]["parts"].append({"text": content})
                else:
                    gemini_messages.append({
                        "role": "user",
                        "parts": [{
                            "text": content
                        }]
                    })
            elif role == "user":
                user_parts = [{"text": content}]

                # æ·»åŠ å›¾åƒï¼ˆå¦‚æœæœ‰ä¸”æ˜¯æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ï¼‰
                if images and msg == messages[-1] and msg["role"] == "user":
                    for img in images:
                        user_parts.append({
                            "inline_data": {
                                "mime_type": "image/jpeg",
                                "data": img["data"]
                            }
                        })

                gemini_messages.append({"role": "user", "parts": user_parts})
            elif role == "assistant":
                gemini_messages.append({
                    "role": "model",
                    "parts": [{
                        "text": content
                    }]
                })

        return {
            "contents": gemini_messages,
            "generationConfig": {
                "temperature": provider["temperature"]
            },
            "stream": stream
        }

    @staticmethod
    def parse_response(response_data: Dict[str, Any]) -> str:
        """è§£æ Gemini å“åº”"""
        try:
            return response_data["candidates"][0]["content"]["parts"][0][
                "text"]
        except (KeyError, IndexError) as e:
            _interface.logger.error(f"è§£æ Gemini å“åº”å¤±è´¥: {e}")
            return None

    @staticmethod
    async def process_stream(line: bytes, callback: Callable[[str], None],
                             full_response: str) -> str:
        """å¤„ç† Gemini æµå¼å“åº”"""
        if not line.strip():
            return full_response

        try:
            json_data = json.loads(line)

            # æå–æ–‡æœ¬å†…å®¹
            if 'candidates' in json_data and json_data['candidates']:
                candidate = json_data['candidates'][0]
                if 'content' in candidate and 'parts' in candidate['content']:
                    for part in candidate['content']['parts']:
                        if 'text' in part and part['text']:
                            content = part['text']
                            full_response += content

                            # åªæœ‰å½“æœ‰å®é™…å†…å®¹æ—¶æ‰è°ƒç”¨å›è°ƒ
                            if full_response.strip():
                                await callback(full_response)
        except Exception as e:
            _interface.logger.error(f"è§£æ Gemini æµå¼å“åº”å¤±è´¥: {e}")

        return full_response


class AnthropicProvider:
    """Anthropic Claude æœåŠ¡æä¾›å•†å®ç°"""

    @staticmethod
    def format_request(provider: Dict[str, Any],
                       messages: List[Dict[str, str]],
                       images: Optional[List[Dict[str, Any]]] = None,
                       stream: bool = False) -> Dict[str, Any]:
        """æ ¼å¼åŒ– Anthropic è¯·æ±‚"""
        # æå–ç³»ç»Ÿæç¤º
        system = ""
        for msg in messages:
            if msg["role"] == "system":
                system = msg["content"]
                break

        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        anthropic_messages = []

        for msg in messages:
            if msg["role"] == "user":
                # å¤„ç†ç”¨æˆ·æ¶ˆæ¯ï¼Œå¯èƒ½åŒ…å«å›¾åƒ
                if images and msg == messages[-1]:
                    # æ„å»ºåŒ…å«å›¾åƒçš„å†…å®¹
                    content = [{"type": "text", "text": msg["content"]}]

                    # æ·»åŠ å›¾åƒ
                    for img in images:
                        content.append({
                            "type": "image",
                            "source": {
                                "type": "base64",
                                "media_type": "image/jpeg",
                                "data": img["data"]
                            }
                        })

                    anthropic_messages.append({
                        "role": "user",
                        "content": content
                    })
                else:
                    # æ™®é€šæ–‡æœ¬æ¶ˆæ¯
                    anthropic_messages.append({
                        "role": "user",
                        "content": msg["content"]
                    })
            elif msg["role"] == "assistant":
                anthropic_messages.append({
                    "role": "assistant",
                    "content": msg["content"]
                })

        # æ„å»ºè¯·æ±‚
        request = {
            "model": provider["model"],
            "messages": anthropic_messages,
            "temperature": provider["temperature"],
            "max_tokens": 4000,
            "stream": stream
        }

        # æ·»åŠ ç³»ç»Ÿæç¤º (å¦‚æœæœ‰)
        if system:
            request["system"] = system

        return request

    @staticmethod
    def parse_response(response_data: Dict[str, Any]) -> str:
        """è§£æ Anthropic å“åº”"""
        try:
            if isinstance(response_data.get("content"), list):
                text_blocks = [
                    block["text"] for block in response_data["content"]
                    if block["type"] == "text"
                ]
                return "".join(text_blocks)
            return None
        except (KeyError, IndexError) as e:
            _interface.logger.error(f"è§£æ Anthropic å“åº”å¤±è´¥: {e}")
            return None

    @staticmethod
    async def process_stream(line: bytes, callback: Callable[[str], None],
                             full_response: str) -> str:
        """å¤„ç† Anthropic æµå¼å“åº”"""
        if not line or line == b'data: [DONE]':
            return full_response

        try:
            # ç§»é™¤ "data: " å‰ç¼€å¹¶è§£æ JSON
            if line.startswith(b'data: '):
                json_data = json.loads(line[6:])

                if 'type' in json_data and json_data[
                        'type'] == 'content_block_delta':
                    delta = json_data.get('delta', {})
                    if 'text' in delta and delta['text']:
                        content = delta['text']
                        full_response += content

                        # åªæœ‰å½“æœ‰å®é™…å†…å®¹æ—¶æ‰è°ƒç”¨å›è°ƒ
                        if full_response.strip():
                            await callback(full_response)
        except Exception as e:
            _interface.logger.error(f"è§£æ Anthropic æµå¼å“åº”å¤±è´¥: {e}")

        return full_response


class ConversationManager:
    """ç”¨æˆ·å¯¹è¯ç®¡ç†"""

    @staticmethod
    def get_user_context(user_id: Union[int, str]) -> List[Dict[str, Any]]:
        """è·å–ç”¨æˆ·å¯¹è¯ä¸Šä¸‹æ–‡
        
        Args:
            user_id: ç”¨æˆ· ID
            
        Returns:
            List[Dict]: ç”¨æˆ·å¯¹è¯ä¸Šä¸‹æ–‡
        """
        global _state
        user_id_str = str(user_id)

        if user_id_str not in _state["conversations"]:
            # åˆå§‹åŒ–æ–°ç”¨æˆ·çš„ä¸Šä¸‹æ–‡
            _state["conversations"][user_id_str] = []

        return _state["conversations"][user_id_str]

    @staticmethod
    def add_message(user_id: Union[int, str], role: str,
                    content: str) -> List[Dict[str, Any]]:
        """æ·»åŠ æ¶ˆæ¯åˆ°ç”¨æˆ·ä¸Šä¸‹æ–‡
        
        Args:
            user_id: ç”¨æˆ· ID
            role: æ¶ˆæ¯è§’è‰² (user, assistant, system)
            content: æ¶ˆæ¯å†…å®¹
            
        Returns:
            List[Dict]: æ›´æ–°åçš„ç”¨æˆ·ä¸Šä¸‹æ–‡
        """
        global _state
        user_id_str = str(user_id)
        context = ConversationManager.get_user_context(user_id_str)

        # æ·»åŠ æ–°æ¶ˆæ¯
        context.append({
            "role": role,
            "content": content,
            "timestamp": time.time()
        })

        # é™åˆ¶ä¸Šä¸‹æ–‡é•¿åº¦
        if len(context) > MAX_CONTEXT_LENGTH * 2:  # æˆå¯¹é™åˆ¶ (ç”¨æˆ· + åŠ©æ‰‹)
            # ä¿ç•™ç³»ç»Ÿæ¶ˆæ¯ (å¦‚æœæœ‰) å’Œæœ€è¿‘çš„æ¶ˆæ¯
            system_messages = [
                msg for msg in context if msg["role"] == "system"
            ]
            recent_messages = context[-MAX_CONTEXT_LENGTH * 2:]
            context = system_messages + recent_messages
            _state["conversations"][user_id_str] = context

        # æ›´æ–°ç”¨æˆ·ç»Ÿè®¡
        if role == "user":
            _state["usage_stats"]["requests_by_user"][user_id_str] = \
                _state["usage_stats"]["requests_by_user"].get(user_id_str, 0) + 1

        # ä¿å­˜ä¸Šä¸‹æ–‡
        save_contexts()

        return context

    @staticmethod
    def clear_context(user_id: Union[int, str]) -> bool:
        """æ¸…é™¤ç”¨æˆ·å¯¹è¯ä¸Šä¸‹æ–‡ï¼Œä¿ç•™ç³»ç»Ÿæç¤º
        
        Args:
            user_id: ç”¨æˆ· ID
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸæ¸…é™¤
        """
        global _state
        user_id_str = str(user_id)

        if user_id_str in _state["conversations"]:
            # ä¿ç•™ç³»ç»Ÿæç¤º
            system_messages = [
                msg for msg in _state["conversations"][user_id_str]
                if msg["role"] == "system"
            ]
            _state["conversations"][user_id_str] = system_messages
            save_contexts()
            return True

        return False

    @staticmethod
    def cleanup_expired() -> int:
        """æ¸…ç†è¿‡æœŸçš„å¯¹è¯
        
        Returns:
            int: æ¸…ç†çš„å¯¹è¯æ•°é‡
        """
        global _state
        now = time.time()
        timeout = _state.get("conversation_timeout", 24 * 60 * 60)  # é»˜è®¤ 24 å°æ—¶
        expired_count = 0

        for user_id, context in list(_state["conversations"].items()):
            if not context:
                continue

            # è·å–æœ€åä¸€æ¡æ¶ˆæ¯çš„æ—¶é—´
            last_message_time = max(
                [msg.get("timestamp", 0) for msg in context]) if context else 0

            # å¦‚æœè¶…è¿‡è¶…æ—¶æ—¶é—´ï¼Œæ¸…é™¤å¯¹è¯ï¼ˆä¿ç•™ç³»ç»Ÿæ¶ˆæ¯ï¼‰
            if now - last_message_time > timeout:
                system_messages = [
                    msg for msg in context if msg["role"] == "system"
                ]
                _state["conversations"][user_id] = system_messages
                expired_count += 1

        return expired_count

    @staticmethod
    def format_for_api(provider_id: str,
                       user_id: Union[int, str]) -> List[Dict[str, str]]:
        """æ ¼å¼åŒ–ç”¨æˆ·ä¸Šä¸‹æ–‡ä¸º API è¯·æ±‚æ ¼å¼
        
        Args:
            provider_id: æœåŠ¡å•† ID
            user_id: ç”¨æˆ· ID
            
        Returns:
            List[Dict]: æ ¼å¼åŒ–çš„æ¶ˆæ¯åˆ—è¡¨
        """
        global _state

        provider_data = _state["providers"].get(provider_id)
        if not provider_data:
            return []

        # è·å–ç”¨æˆ·ä¸Šä¸‹æ–‡
        context = ConversationManager.get_user_context(user_id)

        # æ·»åŠ ç³»ç»Ÿæç¤ºä½œä¸ºç¬¬ä¸€æ¡æ¶ˆæ¯ (å¦‚æœä¸å­˜åœ¨)
        has_system = any(msg["role"] == "system" for msg in context)

        messages = []
        if not has_system and provider_data.get("system_prompt"):
            messages.append({
                "role": "system",
                "content": provider_data["system_prompt"]
            })

        # æ·»åŠ ä¸Šä¸‹æ–‡æ¶ˆæ¯ (å»æ‰æ—¶é—´æˆ³)
        for msg in context:
            if msg["role"] in ["user", "assistant", "system"]:
                messages.append({
                    "role": msg["role"],
                    "content": msg["content"]
                })

        return messages


class AIManager:
    """AI åŠŸèƒ½ç®¡ç†ç±»"""

    @staticmethod
    async def call_ai_api(
            provider_id: str,
            messages: List[Dict[str, str]],
            images: Optional[List[Dict[str, Any]]] = None,
            stream: bool = False,
            update_callback: Optional[Callable[[str], Any]] = None) -> str:
        """è°ƒç”¨ AI API
        
        Args:
            provider_id: æœåŠ¡å•† ID
            messages: æ¶ˆæ¯åˆ—è¡¨
            images: å›¾åƒåˆ—è¡¨ (å¯é€‰)
            stream: æ˜¯å¦ä½¿ç”¨æµå¼æ¨¡å¼
            update_callback: æµå¼æ›´æ–°å›è°ƒå‡½æ•°
            
        Returns:
            str: API å“åº”æ–‡æœ¬
        """
        global _state

        # æ£€æŸ¥å¹¶åˆå§‹åŒ–è¯·æ±‚é”
        if _state["request_lock"] is None:
            _state["request_lock"] = asyncio.Lock()

        # æ£€æŸ¥å¹¶å‘è¯·æ±‚æ•°
        async with _state["request_lock"]:
            if _state["concurrent_requests"] >= MAX_CONCURRENT_REQUESTS:
                return "âš ï¸ ç³»ç»Ÿæ­£åœ¨å¤„ç†è¿‡å¤šè¯·æ±‚ï¼Œè¯·ç¨åå†è¯•"

            _state["concurrent_requests"] += 1

        try:
            # æ£€æŸ¥æœåŠ¡å•†
            if provider_id not in _state["providers"]:
                return "é”™è¯¯ï¼šæœªæ‰¾åˆ°æŒ‡å®šçš„æœåŠ¡å•†é…ç½®"

            provider = _state["providers"][provider_id]

            # æ£€æŸ¥ API å¯†é’¥
            if not provider.get("api_key"):
                return "é”™è¯¯ï¼šæœªé…ç½® API å¯†é’¥"

            # å‡†å¤‡è¯·æ±‚æ•°æ®
            try:
                request_data = await AIServiceProvider.format_request(
                    provider, messages, images, stream)
            except Exception as e:
                _interface.logger.error(f"æ ¼å¼åŒ–è¯·æ±‚å¤±è´¥: {e}")
                return f"æ ¼å¼åŒ–è¯·æ±‚å¤±è´¥: {str(e)}"

            # å‡†å¤‡ API è¯·æ±‚
            try:
                api_url, headers = await AIServiceProvider.prepare_api_request(
                    provider, request_data)
            except Exception as e:
                _interface.logger.error(f"å‡†å¤‡ API è¯·æ±‚å¤±è´¥: {e}")
                return f"å‡†å¤‡ API è¯·æ±‚å¤±è´¥: {str(e)}"

            # æµå¼æ¨¡å¼
            if stream and update_callback:
                return await AIManager._stream_request(provider, api_url,
                                                       headers, request_data,
                                                       update_callback,
                                                       provider_id)

            # éæµå¼æ¨¡å¼
            return await AIManager._standard_request(provider, api_url,
                                                     headers, request_data,
                                                     provider_id)

        finally:
            # å‡å°‘å¹¶å‘è¯·æ±‚è®¡æ•°
            async with _state["request_lock"]:
                _state["concurrent_requests"] -= 1

    @staticmethod
    async def _stream_request(provider: Dict[str, Any], api_url: str,
                              headers: Dict[str, str], request_data: Dict[str,
                                                                          Any],
                              update_callback: Callable[[str], Any],
                              provider_id: str) -> str:
        """å¤„ç†æµå¼ API è¯·æ±‚
        
        Args:
            provider: æœåŠ¡å•†é…ç½®
            api_url: API URL
            headers: è¯·æ±‚å¤´
            request_data: è¯·æ±‚æ•°æ®
            update_callback: æ›´æ–°å›è°ƒå‡½æ•°
            provider_id: æœåŠ¡å•† ID
            
        Returns:
            str: å®Œæ•´å“åº”æ–‡æœ¬
        """
        global _state

        request_format = provider.get("request_format", "openai")
        full_response = ""
        last_update_time = time.time()

        try:
            _interface.logger.debug(f"æ­£åœ¨æµå¼è°ƒç”¨ {provider['name']} API")

            async with aiohttp.ClientSession() as session:
                async with session.post(api_url,
                                        json=request_data,
                                        headers=headers,
                                        timeout=REQUEST_TIMEOUT) as response:

                    if response.status != 200:
                        error_text = await response.text()
                        _interface.logger.error(
                            f"API è¯·æ±‚å¤±è´¥: {response.status} - {error_text}")
                        return f"API è¯·æ±‚å¤±è´¥: HTTP {response.status}"

                    # æ ¹æ®ä¸åŒæœåŠ¡å•†å¤„ç†æµå¼å“åº”
                    if request_format == "openai":
                        # OpenAI æµå¼å“åº”å¤„ç†
                        async for line in response.content:
                            line = line.strip()

                            # å¤„ç†æµå¼å“åº”è¡Œ
                            full_response = await OpenAIProvider.process_stream(
                                line,
                                # åŒ…è£…å›è°ƒä»¥æ§åˆ¶æ›´æ–°é¢‘ç‡
                                lambda text: AIManager._throttled_update(
                                    text, update_callback, last_update_time),
                                full_response)

                            # æ›´æ–°æœ€åæ›´æ–°æ—¶é—´
                            current_time = time.time()
                            if current_time - last_update_time >= MIN_UPDATE_INTERVAL:
                                last_update_time = current_time

                    elif request_format == "anthropic":
                        # Anthropic æµå¼å“åº”å¤„ç†
                        async for line in response.content:
                            line = line.strip()

                            # å¤„ç†æµå¼å“åº”è¡Œ
                            full_response = await AnthropicProvider.process_stream(
                                line,
                                # åŒ…è£…å›è°ƒä»¥æ§åˆ¶æ›´æ–°é¢‘ç‡
                                lambda text: AIManager._throttled_update(
                                    text, update_callback, last_update_time),
                                full_response)

                            # æ›´æ–°æœ€åæ›´æ–°æ—¶é—´
                            current_time = time.time()
                            if current_time - last_update_time >= MIN_UPDATE_INTERVAL:
                                last_update_time = current_time

                    elif request_format == "gemini":
                        # Gemini æµå¼å“åº”å¤„ç†
                        buffer = b""

                        async for chunk in response.content:
                            buffer += chunk

                            # å°è¯•è§£æå®Œæ•´çš„ JSON å¯¹è±¡
                            if b'\n' in buffer:
                                lines = buffer.split(b'\n')
                                # ä¿ç•™æœ€åä¸€ä¸ªå¯èƒ½ä¸å®Œæ•´çš„è¡Œ
                                buffer = lines.pop()

                                for line in lines:
                                    if not line.strip():
                                        continue

                                    # å¤„ç†æµå¼å“åº”è¡Œ
                                    full_response = await GeminiProvider.process_stream(
                                        line,
                                        # åŒ…è£…å›è°ƒä»¥æ§åˆ¶æ›´æ–°é¢‘ç‡
                                        lambda text: AIManager.
                                        _throttled_update(
                                            text, update_callback,
                                            last_update_time),
                                        full_response)

                                    # æ›´æ–°æœ€åæ›´æ–°æ—¶é—´
                                    current_time = time.time()
                                    if current_time - last_update_time >= MIN_UPDATE_INTERVAL:
                                        last_update_time = current_time

            # æ›´æ–°ä½¿ç”¨ç»Ÿè®¡
            _state["usage_stats"]["total_requests"] += 1
            _state["usage_stats"]["requests_by_provider"][provider_id] = \
                _state["usage_stats"]["requests_by_provider"].get(provider_id, 0) + 1

            # ç¡®ä¿å›è°ƒä¸€ä¸ªæœ€ç»ˆå†…å®¹
            if full_response:
                await update_callback(full_response)

            return full_response

        except aiohttp.ClientError as e:
            _interface.logger.error(f"API è¯·æ±‚é”™è¯¯: {str(e)}")
            return f"API è¯·æ±‚é”™è¯¯: {str(e)}"
        except asyncio.TimeoutError:
            _interface.logger.error("API è¯·æ±‚è¶…æ—¶")
            return "API è¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åå†è¯•"
        except Exception as e:
            _interface.logger.error(f"è°ƒç”¨ AI API æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return f"å‘ç”Ÿé”™è¯¯: {str(e)}"

    @staticmethod
    async def _standard_request(provider: Dict[str, Any], api_url: str,
                                headers: Dict[str,
                                              str], request_data: Dict[str,
                                                                       Any],
                                provider_id: str) -> str:
        """å¤„ç†æ ‡å‡† API è¯·æ±‚
        
        Args:
            provider: æœåŠ¡å•†é…ç½®
            api_url: API URL
            headers: è¯·æ±‚å¤´
            request_data: è¯·æ±‚æ•°æ®
            provider_id: æœåŠ¡å•† ID
            
        Returns:
            str: å“åº”æ–‡æœ¬
        """
        global _state

        try:
            _interface.logger.debug(f"æ­£åœ¨è°ƒç”¨ {provider['name']} API")

            async with aiohttp.ClientSession() as session:
                async with session.post(api_url,
                                        json=request_data,
                                        headers=headers,
                                        timeout=REQUEST_TIMEOUT) as response:

                    if response.status != 200:
                        error_text = await response.text()
                        _interface.logger.error(
                            f"API è¯·æ±‚å¤±è´¥: {response.status} - {error_text}")
                        return f"API è¯·æ±‚å¤±è´¥: HTTP {response.status}"

                    response_json = await response.json()

                    # è§£æå“åº”
                    result = await AIServiceProvider.parse_response(
                        provider, response_json)
                    if result is None:
                        _interface.logger.error(
                            f"è§£æ API å“åº”å¤±è´¥: {response_json}")
                        return "è§£æ API å“åº”å¤±è´¥"

                    # æ›´æ–°ä½¿ç”¨ç»Ÿè®¡
                    _state["usage_stats"]["total_requests"] += 1
                    _state["usage_stats"]["requests_by_provider"][provider_id] = \
                        _state["usage_stats"]["requests_by_provider"].get(provider_id, 0) + 1

                    return result

        except aiohttp.ClientError as e:
            _interface.logger.error(f"API è¯·æ±‚é”™è¯¯: {str(e)}")
            return f"API è¯·æ±‚é”™è¯¯: {str(e)}"
        except asyncio.TimeoutError:
            _interface.logger.error("API è¯·æ±‚è¶…æ—¶")
            return "API è¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åå†è¯•"
        except Exception as e:
            _interface.logger.error(f"è°ƒç”¨ AI API æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return f"å‘ç”Ÿé”™è¯¯: {str(e)}"

    @staticmethod
    async def _throttled_update(text: str, callback: Callable[[str], Any],
                                last_update_time: float) -> None:
        """é™åˆ¶æ›´æ–°é¢‘ç‡çš„å›è°ƒåŒ…è£…å™¨
        
        Args:
            text: æ›´æ–°æ–‡æœ¬
            callback: åŸå§‹å›è°ƒå‡½æ•°
            last_update_time: ä¸Šæ¬¡æ›´æ–°æ—¶é—´
        """
        current_time = time.time()
        if current_time - last_update_time >= MIN_UPDATE_INTERVAL:
            await callback(text)

    @staticmethod
    def is_user_authorized(user_id: int,
                           context: ContextTypes.DEFAULT_TYPE,
                           chat_type: str = None) -> bool:
        """æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æœ‰æƒä½¿ç”¨ AI åŠŸèƒ½
        
        Args:
            user_id: ç”¨æˆ· ID
            context: ä¸Šä¸‹æ–‡å¯¹è±¡
            chat_type: èŠå¤©ç±»å‹
            
        Returns:
            bool: æ˜¯å¦æœ‰æƒé™
        """
        global _state

        # è¶…çº§ç®¡ç†å‘˜æ€»æ˜¯å¯ä»¥ä½¿ç”¨
        config_manager = context.bot_data.get("config_manager")
        if config_manager and config_manager.is_admin(user_id):
            return True

        # ç™½åå•ç”¨æˆ·å¯ä»¥ä½¿ç”¨
        if user_id in _state["whitelist"]:
            return True

        # å…¶ä»–ç”¨æˆ·ä¸èƒ½ä½¿ç”¨
        return False

    @staticmethod
    async def process_image(photo_file: File) -> Optional[Dict[str, str]]:
        """å¤„ç†å›¾åƒæ–‡ä»¶
        
        Args:
            photo_file: Telegram å›¾åƒæ–‡ä»¶
            
        Returns:
            Dict: å¤„ç†åçš„å›¾åƒæ•°æ®ï¼ŒåŒ…å« base64 ç¼–ç 
        """
        try:
            # ä¸‹è½½å›¾åƒ
            image_data = await photo_file.download_as_bytearray()

            # è½¬æ¢ä¸º base64
            image_base64 = base64.b64encode(image_data).decode('utf-8')

            return {"data": image_base64, "mime_type": "image/jpeg"}
        except Exception as e:
            _interface.logger.error(f"å¤„ç†å›¾åƒå¤±è´¥: {e}")
            return None


class ConfigHandler:
    """é…ç½®å‘½ä»¤å¤„ç†å™¨"""

    @staticmethod
    async def show_config(update: Update,
                          context: ContextTypes.DEFAULT_TYPE) -> None:
        """æ˜¾ç¤ºå½“å‰ AI é…ç½®"""
        global _state

        # æ„å»ºé…ç½®ä¿¡æ¯ï¼ˆä½¿ç”¨ HTML æ ¼å¼ï¼‰
        config_text = "<b>ğŸ¤– AI é…ç½®é¢æ¿</b>\n\n"

        # é»˜è®¤æœåŠ¡å•†
        default_provider = _state["default_provider"]
        if default_provider and default_provider in _state["providers"]:
            provider_name = _state["providers"][default_provider].get(
                "name", default_provider)
            config_text += f"<b>å½“å‰é»˜è®¤æœåŠ¡å•†:</b> <code>{default_provider}</code> ({provider_name})\n\n"
        else:
            config_text += f"<b>å½“å‰é»˜è®¤æœåŠ¡å•†:</b> <i>æœªè®¾ç½®</i>\n\n"

        # å¯¹è¯è¶…æ—¶è®¾ç½®
        timeout_hours = _state.get("conversation_timeout",
                                   24 * 60 * 60) // 3600
        config_text += f"<b>å¯¹è¯è¶…æ—¶æ—¶é—´:</b> <code>{timeout_hours}</code> å°æ—¶\n\n"

        # æœåŠ¡å•†åˆ—è¡¨
        config_text += "<b>å·²é…ç½®çš„æœåŠ¡å•†:</b>\n"

        if not _state["providers"]:
            config_text += "<i>æš‚æ— æœåŠ¡å•†é…ç½®ï¼Œè¯·ä½¿ç”¨</i> <code>/aiconfig new</code> <i>åˆ›å»ºæœåŠ¡å•†</i>\n"
        else:
            # æ£€æŸ¥æ˜¯å¦æœ‰å®Œå…¨é…ç½®çš„æœåŠ¡å•†ï¼ˆæœ‰ API å¯†é’¥çš„ï¼‰
            configured_providers = [
                p for p, data in _state["providers"].items()
                if data.get("api_key")
            ]

            if not configured_providers:
                config_text += "<i>å·²åˆ›å»ºæœåŠ¡å•†ï¼Œä½†å°šæœªé…ç½® API å¯†é’¥ã€‚è¯·ä½¿ç”¨</i> <code>/aiconfig provider &lt;ID&gt; api_key YOUR_KEY</code> <i>é…ç½®</i>\n\n"

            # æ˜¾ç¤ºæ‰€æœ‰æœåŠ¡å•†
            for provider_id, provider in _state["providers"].items():
                # æ ‡è®°é»˜è®¤æœåŠ¡å•†å’Œé…ç½®çŠ¶æ€
                is_default = "âœ… " if provider_id == default_provider else ""
                is_configured = "ğŸ”‘ " if provider.get("api_key") else "âš ï¸ "

                config_text += f"\n{is_default}{is_configured}<b>{provider_id}</b>\n"
                config_text += f"  ğŸ“ åç§°: <code>{provider.get('name', provider_id)}</code>\n"
                config_text += f"  ğŸ¤– æ¨¡å‹: <code>{provider.get('model', 'æœªè®¾ç½®')}</code>\n"

                # API URL (å¯èƒ½å¾ˆé•¿ï¼Œæˆªæ–­æ˜¾ç¤º)
                api_url = provider.get('api_url', 'æœªè®¾ç½®')
                if len(api_url) > 20:
                    api_url = api_url[:17] + "..."
                config_text += f"  ğŸ”— API URL: <code>{api_url}</code>\n"

                # API Key (éšè—æ˜¾ç¤º)
                api_key = provider.get('api_key', '')
                if api_key:
                    masked_key = f"{api_key[:4]}...{api_key[-4:]}" if len(
                        api_key) > 8 else "****"
                    config_text += f"  ğŸ”‘ API Key: <code>{masked_key}</code>\n"
                else:
                    config_text += "  ğŸ”‘ API Key: <code>æœªè®¾ç½®</code> âš ï¸\n"

                config_text += f"  ğŸŒ¡ï¸ æ¸©åº¦: <code>{provider.get('temperature', 0.7)}</code>\n"

                # ç³»ç»Ÿæç¤º (å¯èƒ½å¾ˆé•¿ï¼Œæˆªæ–­æ˜¾ç¤º)
                system_prompt = provider.get('system_prompt', 'æœªè®¾ç½®')
                if len(system_prompt) > 12:
                    system_prompt = system_prompt[:9] + "..."
                config_text += f"  ğŸ’¬ ç³»ç»Ÿæç¤º: <code>{system_prompt}</code>\n"

                config_text += f"  ğŸ“‹ è¯·æ±‚æ ¼å¼: <code>{provider.get('request_format', 'openai')}</code>\n"

                # å›¾åƒæ”¯æŒ
                supports_image = "âœ…" if provider.get("supports_image",
                                                     False) else "âŒ"
                config_text += f"  ğŸ–¼ï¸ å›¾åƒæ”¯æŒ: {supports_image}\n"

        # æ·»åŠ ä½¿ç”¨è¯´æ˜
        config_text += "\n<b>ğŸ“š é…ç½®å‘½ä»¤:</b>\n"
        config_text += "â€¢ <code>/aiconfig provider &lt;ID&gt; &lt;å‚æ•°&gt; &lt;å€¼&gt;</code> - é…ç½®æœåŠ¡å•†å‚æ•°\n"
        config_text += "â€¢ <code>/aiconfig new &lt;ID&gt; [æ¨¡æ¿]</code> - åˆ›å»ºæ–°æœåŠ¡å•†\n"
        config_text += "â€¢ <code>/aiconfig default &lt;ID&gt;</code> - è®¾ç½®é»˜è®¤æœåŠ¡å•†\n"
        config_text += "â€¢ <code>/aiconfig delete &lt;ID&gt;</code> - åˆ é™¤æœåŠ¡å•†\n"
        config_text += "â€¢ <code>/aiconfig test &lt;ID&gt;</code> - æµ‹è¯•æœåŠ¡å•†\n"
        config_text += "â€¢ <code>/aiconfig stats</code> - æŸ¥çœ‹ä½¿ç”¨ç»Ÿè®¡\n"
        config_text += "â€¢ <code>/aiconfig timeout &lt;å°æ—¶æ•°&gt;</code> - è®¾ç½®å¯¹è¯è¶…æ—¶æ—¶é—´\n"

        try:
            await update.message.reply_text(config_text, parse_mode="HTML")
        except Exception as e:
            # å¦‚æœå‘é€å¤±è´¥ï¼ˆå¯èƒ½æ˜¯ HTML æ ¼å¼é—®é¢˜ï¼‰ï¼Œå‘é€çº¯æ–‡æœ¬
            _interface.logger.error(f"å‘é€ AI é…ç½®ä¿¡æ¯å¤±è´¥: {e}")
            await update.message.reply_text("å‘é€é…ç½®ä¿¡æ¯å¤±è´¥ï¼Œè¯·è”ç³»ç®¡ç†å‘˜æŸ¥çœ‹æ—¥å¿—")

    @staticmethod
    async def show_stats(update: Update,
                         context: ContextTypes.DEFAULT_TYPE) -> None:
        """æ˜¾ç¤º AI ä½¿ç”¨ç»Ÿè®¡"""
        global _state

        stats = _state["usage_stats"]

        stats_text = "<b>ğŸ“Š AI ä½¿ç”¨ç»Ÿè®¡</b>\n\n"

        # æ€»è¯·æ±‚æ•°
        stats_text += f"<b>æ€»è¯·æ±‚æ•°:</b> <code>{stats.get('total_requests', 0)}</code>\n\n"

        # æŒ‰æœåŠ¡å•†ç»Ÿè®¡
        stats_text += "<b>æŒ‰æœåŠ¡å•†ç»Ÿè®¡:</b>\n"
        if not stats.get('requests_by_provider'):
            stats_text += "<i>æš‚æ— æ•°æ®</i>\n"
        else:
            for provider, count in stats.get('requests_by_provider',
                                             {}).items():
                provider_name = _state["providers"].get(provider, {}).get(
                    "name",
                    provider) if provider in _state["providers"] else provider
                stats_text += f"â€¢ <code>{provider}</code> ({provider_name}): <code>{count}</code>\n"

        # æŒ‰ç”¨æˆ·ç»Ÿè®¡ (ä»…æ˜¾ç¤ºå‰10ä½æ´»è·ƒç”¨æˆ·)
        stats_text += "\n<b>æŒ‰ç”¨æˆ·ç»Ÿè®¡ (å‰10ä½):</b>\n"
        if not stats.get('requests_by_user'):
            stats_text += "<i>æš‚æ— æ•°æ®</i>\n"
        else:
            # æŒ‰ä½¿ç”¨é‡æ’åº
            sorted_users = sorted(stats.get('requests_by_user', {}).items(),
                                  key=lambda x: x[1],
                                  reverse=True)[:10]

            for user_id, count in sorted_users:
                stats_text += f"â€¢ ç”¨æˆ· <code>{user_id}</code>: <code>{count}</code> æ¬¡è¯·æ±‚\n"

        try:
            await update.message.reply_text(stats_text, parse_mode="HTML")
        except Exception as e:
            _interface.logger.error(f"å‘é€ AI ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            await update.message.reply_text("å‘é€ç»Ÿè®¡ä¿¡æ¯å¤±è´¥ï¼Œè¯·è”ç³»ç®¡ç†å‘˜æŸ¥çœ‹æ—¥å¿—")

    @staticmethod
    async def show_whitelist(update: Update,
                             context: ContextTypes.DEFAULT_TYPE) -> None:
        """æ˜¾ç¤ºå½“å‰ AI ç™½åå•"""
        global _state

        whitelist_text = "<b>ğŸ‘¥ AI ç™½åå•ç”¨æˆ·</b>\n\n"

        if not _state["whitelist"]:
            whitelist_text += "<i>ç™½åå•ä¸ºç©º</i>\n"
        else:
            for i, user_id in enumerate(_state["whitelist"], 1):
                whitelist_text += f"{i}. <code>{user_id}</code>\n"

        whitelist_text += "\n<b>ğŸ“š ç™½åå•ç®¡ç†å‘½ä»¤:</b>\n"
        whitelist_text += "â€¢ <code>/aiwhitelist add &lt;ç”¨æˆ·ID&gt;</code> - æ·»åŠ ç”¨æˆ·åˆ°ç™½åå•\n"
        whitelist_text += "â€¢ <code>/aiwhitelist remove &lt;ç”¨æˆ·ID&gt;</code> - ä»ç™½åå•ä¸­ç§»é™¤ç”¨æˆ·\n"
        whitelist_text += "â€¢ <code>/aiwhitelist clear</code> - æ¸…ç©ºç™½åå•\n"
        whitelist_text += "\nğŸ’¡ æç¤ºï¼šå›å¤ç”¨æˆ·æ¶ˆæ¯å¹¶ä½¿ç”¨ <code>/aiwhitelist add</code> å¯å¿«é€Ÿæ·»åŠ è¯¥ç”¨æˆ·\n"

        try:
            await update.message.reply_text(whitelist_text, parse_mode="HTML")
        except Exception as e:
            _interface.logger.error(f"å‘é€ AI ç™½åå•ä¿¡æ¯å¤±è´¥: {e}")
            await update.message.reply_text("å‘é€ç™½åå•ä¿¡æ¯å¤±è´¥ï¼Œè¯·è”ç³»ç®¡ç†å‘˜æŸ¥çœ‹æ—¥å¿—")


# å‘½ä»¤å¤„ç†å‡½æ•°


async def ai_config_command(update: Update,
                            context: ContextTypes.DEFAULT_TYPE) -> None:
    """å¤„ç† /aiconfig å‘½ä»¤ - é…ç½® AI è®¾ç½®"""
    global _state

    # æ£€æŸ¥æ˜¯å¦æ˜¯ç§èŠ
    if update.effective_chat.type != "private":
        await update.message.reply_text("âš ï¸ å‡ºäºå®‰å…¨è€ƒè™‘ï¼ŒAI é…ç½®åªèƒ½åœ¨ç§èŠä¸­è¿›è¡Œ")
        return

    # è§£æå‚æ•°
    if not context.args:
        # æ˜¾ç¤ºå½“å‰é…ç½®
        await ConfigHandler.show_config(update, context)
        return

    # é…ç½®å‘½ä»¤æ ¼å¼: /aiconfig <æ“ä½œ> [å‚æ•°...]
    operation = context.args[0].lower()

    if operation == "provider":
        # é…ç½®æœåŠ¡å•†: /aiconfig provider <provider_id> <å‚æ•°> <å€¼>
        if len(context.args) < 4:
            await update.message.reply_text(
                "ç”¨æ³•: `/aiconfig provider <provider_id> <å‚æ•°> <å€¼>`\n"
                "å‚æ•°å¯ä»¥æ˜¯: name, api\\_url, api\\_key, model, temperature, system\\_prompt, request\\_format, supports\\_image",
                parse_mode="MARKDOWN")
            return

        provider_id = context.args[1]
        param = context.args[2]
        value = " ".join(context.args[3:])

        # æ£€æŸ¥æœåŠ¡å•†æ˜¯å¦å­˜åœ¨
        if provider_id not in _state[
                "providers"] and provider_id not in PROVIDER_TEMPLATES:
            await update.message.reply_text(f"æœªçŸ¥çš„æœåŠ¡å•† ID: `{provider_id}`",
                                            parse_mode="MARKDOWN")
            return

        # å¦‚æœæ˜¯æ–°æœåŠ¡å•†ï¼Œä»æ¨¡æ¿åˆ›å»º
        if provider_id not in _state["providers"]:
            if provider_id in PROVIDER_TEMPLATES:
                _state["providers"][provider_id] = PROVIDER_TEMPLATES[
                    provider_id].copy()
            else:
                _state["providers"][provider_id] = PROVIDER_TEMPLATES[
                    "custom"].copy()
                _state["providers"][provider_id]["name"] = provider_id

        # æ›´æ–°å‚æ•°
        valid_params = [
            "name", "api_url", "api_key", "model", "temperature",
            "system_prompt", "request_format", "supports_image"
        ]

        if param not in valid_params:
            # è½¬ä¹‰å‚æ•°åç§°ï¼Œé˜²æ­¢è¢«è§£é‡Šä¸º Markdown æ ¼å¼
            valid_params_escaped = [
                p.replace("_", "\\_") for p in valid_params
            ]
            await update.message.reply_text(
                f"æ— æ•ˆçš„å‚æ•°: `{param}`\n"
                f"æœ‰æ•ˆå‚æ•°: {', '.join(valid_params_escaped)}",
                parse_mode="MARKDOWN")
            return

        # ç‰¹æ®Šå¤„ç† temperature (è½¬æ¢ä¸ºæµ®ç‚¹æ•°)
        if param == "temperature":
            try:
                value = float(value)
                if not (0.0 <= value <= 1.0):
                    await update.message.reply_text(
                        "temperature å¿…é¡»åœ¨ 0.0 åˆ° 1.0 ä¹‹é—´")
                    return
            except ValueError:
                await update.message.reply_text("temperature å¿…é¡»æ˜¯æœ‰æ•ˆçš„æµ®ç‚¹æ•°")
                return

        # ç‰¹æ®Šå¤„ç† supports_image (è½¬æ¢ä¸ºå¸ƒå°”å€¼)
        if param == "supports_image":
            value = value.lower() in ["true", "yes", "1", "y", "t"]

        # æ›´æ–°å‚æ•°
        _state["providers"][provider_id][param] = value

        # ä¿å­˜é…ç½®
        save_config()

        await update.message.reply_text(
            f"âœ… å·²æ›´æ–°æœåŠ¡å•† `{provider_id}` çš„ `{param}` å‚æ•°", parse_mode="MARKDOWN")
        _interface.logger.info(
            f"ç”¨æˆ· {update.effective_user.id} æ›´æ–°äº†æœåŠ¡å•† {provider_id} çš„ {param} å‚æ•°")

    elif operation == "default":
        # è®¾ç½®é»˜è®¤æœåŠ¡å•†: /aiconfig default <provider_id>
        if len(context.args) < 2:
            await update.message.reply_text(
                "ç”¨æ³•: `/aiconfig default <provider_id>`", parse_mode="MARKDOWN")
            return

        provider_id = context.args[1]

        # æ£€æŸ¥æœåŠ¡å•†æ˜¯å¦å­˜åœ¨
        if provider_id not in _state["providers"]:
            await update.message.reply_text(f"æœªçŸ¥çš„æœåŠ¡å•† ID: `{provider_id}`",
                                            parse_mode="MARKDOWN")
            return

        # æ›´æ–°é»˜è®¤æœåŠ¡å•†
        _state["default_provider"] = provider_id

        # ä¿å­˜é…ç½®
        save_config()

        await update.message.reply_text(f"âœ… å·²å°†é»˜è®¤æœåŠ¡å•†è®¾ç½®ä¸º: `{provider_id}`",
                                        parse_mode="MARKDOWN")
        _interface.logger.info(
            f"ç”¨æˆ· {update.effective_user.id} å°†é»˜è®¤æœåŠ¡å•†è®¾ç½®ä¸º {provider_id}")

    elif operation == "delete":
        # åˆ é™¤æœåŠ¡å•†: /aiconfig delete <provider_id>
        if len(context.args) < 2:
            await update.message.reply_text(
                "ç”¨æ³•: `/aiconfig delete <provider_id>`", parse_mode="MARKDOWN")
            return

        provider_id = context.args[1]

        # æ£€æŸ¥æœåŠ¡å•†æ˜¯å¦å­˜åœ¨
        if provider_id not in _state["providers"]:
            await update.message.reply_text(f"æœªçŸ¥çš„æœåŠ¡å•† ID: `{provider_id}`",
                                            parse_mode="MARKDOWN")
            return

        # å¦‚æœåˆ é™¤çš„æ˜¯é»˜è®¤æœåŠ¡å•†ï¼Œé‡ç½®é»˜è®¤æœåŠ¡å•†
        if _state["default_provider"] == provider_id:
            _state["default_provider"] = None

        # åˆ é™¤æœåŠ¡å•†
        del _state["providers"][provider_id]

        # ä¿å­˜é…ç½®
        save_config()

        await update.message.reply_text(f"âœ… å·²åˆ é™¤æœåŠ¡å•†: `{provider_id}`",
                                        parse_mode="MARKDOWN")
        _interface.logger.info(
            f"ç”¨æˆ· {update.effective_user.id} åˆ é™¤äº†æœåŠ¡å•† {provider_id}")

    elif operation == "new":
        # åˆ›å»ºæ–°æœåŠ¡å•†: /aiconfig new <provider_id> [template]
        if len(context.args) < 2:
            await update.message.reply_text(
                "ç”¨æ³•: `/aiconfig new <provider_id> [template]`\n"
                f"å¯ç”¨æ¨¡æ¿: {', '.join(PROVIDER_TEMPLATES.keys())}",
                parse_mode="MARKDOWN")
            return

        provider_id = context.args[1]
        template = context.args[2] if len(context.args) > 2 else "custom"

        # æ£€æŸ¥æœåŠ¡å•† ID æ˜¯å¦å·²å­˜åœ¨
        if provider_id in _state["providers"]:
            await update.message.reply_text(f"æœåŠ¡å•† ID å·²å­˜åœ¨: `{provider_id}`",
                                            parse_mode="MARKDOWN")
            return

        # æ£€æŸ¥æ¨¡æ¿æ˜¯å¦å­˜åœ¨
        if template not in PROVIDER_TEMPLATES:
            await update.message.reply_text(
                f"æœªçŸ¥çš„æ¨¡æ¿: `{template}`\n"
                f"å¯ç”¨æ¨¡æ¿: {', '.join(PROVIDER_TEMPLATES.keys())}",
                parse_mode="MARKDOWN")
            return

        # åˆ›å»ºæ–°æœåŠ¡å•†
        _state["providers"][provider_id] = PROVIDER_TEMPLATES[template].copy()
        _state["providers"][provider_id]["name"] = provider_id

        # å¦‚æœæ²¡æœ‰é»˜è®¤æœåŠ¡å•†ï¼Œè®¾ç½®ä¸ºé»˜è®¤
        if not _state["default_provider"]:
            _state["default_provider"] = provider_id

        # ä¿å­˜é…ç½®
        save_config()

        await update.message.reply_text(
            f"âœ… å·²åˆ›å»ºæ–°æœåŠ¡å•†: `{provider_id}` (ä½¿ç”¨ {template} æ¨¡æ¿)\n"
            f"è¯·ä½¿ç”¨ `/aiconfig provider {provider_id} api_key YOUR_API_KEY` è®¾ç½® API å¯†é’¥",
            parse_mode="MARKDOWN")
        _interface.logger.info(
            f"ç”¨æˆ· {update.effective_user.id} åˆ›å»ºäº†æ–°æœåŠ¡å•† {provider_id}")

    elif operation == "test":
        # æµ‹è¯•æœåŠ¡å•†: /aiconfig test <provider_id>
        if len(context.args) < 2:
            await update.message.reply_text(
                "ç”¨æ³•: `/aiconfig test <provider_id>`", parse_mode="MARKDOWN")
            return

        provider_id = context.args[1]

        # æ£€æŸ¥æœåŠ¡å•†æ˜¯å¦å­˜åœ¨
        if provider_id not in _state["providers"]:
            await update.message.reply_text(f"æœªçŸ¥çš„æœåŠ¡å•† ID: `{provider_id}`",
                                            parse_mode="MARKDOWN")
            return

        # å‘é€æµ‹è¯•æ¶ˆæ¯
        await update.message.reply_text(f"ğŸ”„ æ­£åœ¨æµ‹è¯•æœåŠ¡å•† `{provider_id}`...",
                                        parse_mode="MARKDOWN")

        # å‡†å¤‡æµ‹è¯•æ¶ˆæ¯
        test_messages = [{
            "role":
            "user",
            "content":
            "Hello, can you introduce yourself briefly?"
        }]

        # è°ƒç”¨ API
        response = await AIManager.call_ai_api(provider_id, test_messages)

        # æ˜¾ç¤ºå“åº”
        await update.message.reply_text(f"ğŸ“ æµ‹è¯•ç»“æœ:\n\n{response}")

        _interface.logger.info(
            f"ç”¨æˆ· {update.effective_user.id} æµ‹è¯•äº†æœåŠ¡å•† {provider_id}")

    elif operation == "stats":
        # æŸ¥çœ‹ä½¿ç”¨ç»Ÿè®¡: /aiconfig stats
        await ConfigHandler.show_stats(update, context)

    elif operation == "timeout":
        # è®¾ç½®å¯¹è¯è¶…æ—¶æ—¶é—´: /aiconfig timeout <å°æ—¶æ•°>
        if len(context.args) < 2:
            await update.message.reply_text(
                "ç”¨æ³•: `/aiconfig timeout <å°æ—¶æ•°>`\n"
                "å½“å‰è¶…æ—¶æ—¶é—´: " +
                str(_state.get("conversation_timeout", 24 * 60 * 60) // 3600) +
                " å°æ—¶",
                parse_mode="MARKDOWN")
            return

        try:
            hours = float(context.args[1])
            if hours <= 0:
                await update.message.reply_text("è¶…æ—¶æ—¶é—´å¿…é¡»å¤§äº 0 å°æ—¶")
                return

            # æ›´æ–°è¶…æ—¶æ—¶é—´ (è½¬æ¢ä¸ºç§’)
            _state["conversation_timeout"] = int(hours * 3600)

            # ä¿å­˜é…ç½®
            save_config()

            await update.message.reply_text(f"âœ… å·²å°†å¯¹è¯è¶…æ—¶æ—¶é—´è®¾ç½®ä¸º {hours} å°æ—¶")
            _interface.logger.info(
                f"ç”¨æˆ· {update.effective_user.id} å°†å¯¹è¯è¶…æ—¶æ—¶é—´è®¾ç½®ä¸º {hours} å°æ—¶")
        except ValueError:
            await update.message.reply_text("å°æ—¶æ•°å¿…é¡»æ˜¯æœ‰æ•ˆçš„æ•°å­—")

    else:
        # æœªçŸ¥æ“ä½œ
        await update.message.reply_text(
            f"æœªçŸ¥æ“ä½œ: `{operation}`\n"
            "å¯ç”¨æ“ä½œ: provider, default, delete, new, test, stats, timeout",
            parse_mode="MARKDOWN")


async def ai_whitelist_command(update: Update,
                               context: ContextTypes.DEFAULT_TYPE) -> None:
    """å¤„ç† /aiwhitelist å‘½ä»¤ - ç®¡ç† AI ç™½åå•"""
    global _state

    if not context.args:
        # æ˜¾ç¤ºå½“å‰ç™½åå•
        await ConfigHandler.show_whitelist(update, context)
        return

    # è§£æå‘½ä»¤: /aiwhitelist <æ“ä½œ> <ç”¨æˆ·ID>
    operation = context.args[0].lower()

    if operation == "add":
        # æ·»åŠ ç”¨æˆ·åˆ°ç™½åå•
        if len(context.args) < 2 and not update.message.reply_to_message:
            await update.message.reply_text(
                "ç”¨æ³•: `/aiwhitelist add <ç”¨æˆ·ID>`\næˆ–å›å¤æŸäººçš„æ¶ˆæ¯æ·»åŠ ä»–ä»¬",
                parse_mode="MARKDOWN")
            return

        # æ£€æŸ¥æ˜¯å¦æ˜¯å›å¤æŸäººçš„æ¶ˆæ¯
        if update.message.reply_to_message and update.message.reply_to_message.from_user:
            user_id = update.message.reply_to_message.from_user.id
            username = update.message.reply_to_message.from_user.username or "æœªçŸ¥ç”¨æˆ·å"
            full_name = update.message.reply_to_message.from_user.full_name or "æœªçŸ¥å§“å"
        else:
            # ä»å‚æ•°è·å–ç”¨æˆ· ID
            try:
                user_id = int(context.args[1])
                username = "æœªçŸ¥ç”¨æˆ·å"
                full_name = "æœªçŸ¥å§“å"
            except ValueError:
                await update.message.reply_text("ç”¨æˆ· ID å¿…é¡»æ˜¯æ•°å­—")
                return

        # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å·²åœ¨ç™½åå•ä¸­
        if user_id in _state["whitelist"]:
            safe_username = username.replace('.', '\\.').replace('-', '\\-')
            await update.message.reply_text(
                f"ç”¨æˆ· `{user_id}` (@{safe_username}) å·²åœ¨ç™½åå•ä¸­",
                parse_mode="MARKDOWN")
            return

        # æ·»åŠ åˆ°ç™½åå•
        _state["whitelist"].append(user_id)

        # ä¿å­˜é…ç½®
        save_config()

        safe_username = username.replace('.', '\\.').replace('-', '\\-')
        safe_full_name = full_name.replace('.', '\\.').replace('-', '\\-')
        await update.message.reply_text(
            f"âœ… å·²å°†ç”¨æˆ· `{user_id}` (@{safe_username}, {safe_full_name}) æ·»åŠ åˆ°ç™½åå•",
            parse_mode="MARKDOWN")
        _interface.logger.info(
            f"ç”¨æˆ· {update.effective_user.id} å°†ç”¨æˆ· {user_id} æ·»åŠ åˆ° AI ç™½åå•")

    elif operation == "remove":
        # ä»ç™½åå•ä¸­ç§»é™¤ç”¨æˆ·
        if len(context.args) < 2:
            await update.message.reply_text("ç”¨æ³•: `/aiwhitelist remove <ç”¨æˆ·ID>`",
                                            parse_mode="MARKDOWN")
            return

        try:
            user_id = int(context.args[1])

            # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦åœ¨ç™½åå•ä¸­
            if user_id not in _state["whitelist"]:
                await update.message.reply_text(f"ç”¨æˆ· `{user_id}` ä¸åœ¨ç™½åå•ä¸­",
                                                parse_mode="MARKDOWN")
                return

            # ä»ç™½åå•ä¸­ç§»é™¤
            _state["whitelist"].remove(user_id)

            # ä¿å­˜é…ç½®
            save_config()

            await update.message.reply_text(f"âœ… å·²å°†ç”¨æˆ· `{user_id}` ä»ç™½åå•ä¸­ç§»é™¤",
                                            parse_mode="MARKDOWN")
            _interface.logger.info(
                f"ç”¨æˆ· {update.effective_user.id} å°†ç”¨æˆ· {user_id} ä» AI ç™½åå•ä¸­ç§»é™¤")
        except ValueError:
            await update.message.reply_text("ç”¨æˆ· ID å¿…é¡»æ˜¯æ•°å­—")

    elif operation == "clear":
        # æ¸…ç©ºç™½åå•
        _state["whitelist"] = []

        # ä¿å­˜é…ç½®
        save_config()

        await update.message.reply_text("âœ… å·²æ¸…ç©º AI ç™½åå•")
        _interface.logger.info(f"ç”¨æˆ· {update.effective_user.id} æ¸…ç©ºäº† AI ç™½åå•")

    else:
        # æœªçŸ¥æ“ä½œ
        await update.message.reply_text(
            f"æœªçŸ¥æ“ä½œ: `{operation}`\n"
            "å¯ç”¨æ“ä½œ: add, remove, clear",
            parse_mode="MARKDOWN")


async def ai_clear_command(update: Update,
                           context: ContextTypes.DEFAULT_TYPE) -> None:
    """å¤„ç† /aiclear å‘½ä»¤ - æ¸…é™¤å¯¹è¯ä¸Šä¸‹æ–‡"""
    user_id = update.effective_user.id

    # æ£€æŸ¥æƒé™
    if not AIManager.is_user_authorized(user_id, context,
                                        update.effective_chat.type):
        await update.message.reply_text("âš ï¸ æ‚¨æ²¡æœ‰ä½¿ç”¨ AI åŠŸèƒ½çš„æƒé™\nè¯·è”ç³»ç®¡ç†å‘˜å°†æ‚¨æ·»åŠ åˆ°ç™½åå•")
        _interface.logger.warning(f"ç”¨æˆ· {user_id} å°è¯•ä½¿ç”¨ AI åŠŸèƒ½ä½†æ²¡æœ‰æƒé™")
        return

    # æ¸…é™¤ä¸Šä¸‹æ–‡
    if ConversationManager.clear_context(user_id):
        await update.message.reply_text("âœ… å·²æ¸…é™¤æ‚¨çš„å¯¹è¯å†å²")
        _interface.logger.info(f"ç”¨æˆ· {user_id} æ¸…é™¤äº†å¯¹è¯å†å²")
    else:
        await update.message.reply_text("æ‚¨è¿˜æ²¡æœ‰ä»»ä½•å¯¹è¯å†å²")


async def ai_command(update: Update,
                     context: ContextTypes.DEFAULT_TYPE) -> None:
    """å¤„ç† /ai å‘½ä»¤ - å‘ AI å‘é€æ¶ˆæ¯"""
    user_id = update.effective_user.id

    # æ£€æŸ¥æƒé™
    if not AIManager.is_user_authorized(user_id, context,
                                        update.effective_chat.type):
        await update.message.reply_text("âš ï¸ æ‚¨æ²¡æœ‰ä½¿ç”¨ AI åŠŸèƒ½çš„æƒé™\nè¯·è”ç³»ç®¡ç†å‘˜å°†æ‚¨æ·»åŠ åˆ°ç™½åå•")
        _interface.logger.warning(f"ç”¨æˆ· {user_id} å°è¯•ä½¿ç”¨ AI åŠŸèƒ½ä½†æ²¡æœ‰æƒé™")
        return

    # æ£€æŸ¥æ˜¯å¦æœ‰æ¶ˆæ¯å†…å®¹
    if not context.args:
        await update.message.reply_text(
            "è¯·è¾“å…¥è¦å‘é€ç»™ AI çš„æ¶ˆæ¯\n"
            "ä¾‹å¦‚: `/ai ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±`\n\n"
            "ğŸ”„ ä½¿ç”¨ `/aiclear` å¯æ¸…é™¤å¯¹è¯å†å²\n"
            "ğŸ“· åœ¨ç§èŠä¸­å¯ä»¥å‘é€å›¾ç‰‡å¹¶é™„åŠ æ–‡å­—æè¿°ä½¿ç”¨å¤šæ¨¡æ€åŠŸèƒ½",
            parse_mode="MARKDOWN")
        return

    # è·å–æ¶ˆæ¯å†…å®¹
    message_text = " ".join(context.args)

    # æ£€æŸ¥æ¶ˆæ¯é•¿åº¦
    if len(message_text) > MAX_MESSAGE_LENGTH:
        await update.message.reply_text(
            f"âš ï¸ æ¶ˆæ¯å¤ªé•¿ï¼Œè¯·å°†é•¿åº¦æ§åˆ¶åœ¨ {MAX_MESSAGE_LENGTH} å­—ç¬¦ä»¥å†…")
        return

    # æ£€æŸ¥é»˜è®¤æœåŠ¡å•†
    provider_id = _state["default_provider"]
    if not provider_id or provider_id not in _state["providers"]:
        await update.message.reply_text("âš ï¸ æœªé…ç½®é»˜è®¤ AI æœåŠ¡å•†ï¼Œè¯·è”ç³»ç®¡ç†å‘˜")
        _interface.logger.warning(f"ç”¨æˆ· {user_id} å°è¯•ä½¿ç”¨ AI ä½†æœªé…ç½®é»˜è®¤æœåŠ¡å•†")
        return

    # è·å–å›¾åƒï¼ˆå¦‚æœæœ‰ï¼‰
    replied_message = update.message.reply_to_message
    images = []

    if replied_message and replied_message.photo:
        # å¦‚æœå›å¤çš„æ¶ˆæ¯åŒ…å«å›¾åƒ
        provider = _state["providers"].get(provider_id, {})
        if provider.get("supports_image", False):
            # è·å–æœ€å¤§å°ºå¯¸çš„å›¾åƒ
            photo = replied_message.photo[-1]
            photo_file = await context.bot.get_file(photo.file_id)

            # å¤„ç†å›¾åƒ
            image_data = await AIManager.process_image(photo_file)
            if image_data:
                images.append(image_data)
                await update.message.reply_text("ğŸ“· å·²æ·»åŠ å›¾ç‰‡åˆ°è¯·æ±‚ä¸­")
        else:
            await update.message.reply_text("âš ï¸ å½“å‰æœåŠ¡å•†ä¸æ”¯æŒå›¾åƒå¤„ç†")

    # å‘é€"æ­£åœ¨æ€è€ƒ"æ¶ˆæ¯
    thinking_message = await update.message.reply_text("ğŸ¤” æ­£åœ¨æ€è€ƒä¸­...")

    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°ä¸Šä¸‹æ–‡
    ConversationManager.add_message(user_id, "user", message_text)

    # å‡†å¤‡ API è¯·æ±‚
    messages = ConversationManager.format_for_api(provider_id, user_id)

    # å®Œæ•´å“åº”å˜é‡
    full_response = ""
    is_completed = False

    # åˆ›å»ºæµå¼æ›´æ–°å›è°ƒå‡½æ•°
    async def update_message_callback(text):
        nonlocal full_response
        try:
            # ç¡®ä¿æ–‡æœ¬ä¸ä¸ºç©º
            if not text.strip():
                return

            full_response = text

            # å¦‚æœæ–‡æœ¬å¤ªé•¿ï¼Œåªæ˜¾ç¤ºæœ€åéƒ¨åˆ†
            if len(text) <= MAX_MESSAGE_LENGTH:
                try:
                    await thinking_message.edit_text(text)
                except telegram.error.BadRequest as e:
                    # å¿½ç•¥"æ¶ˆæ¯æœªä¿®æ”¹"é”™è¯¯
                    if "Message is not modified" not in str(e):
                        _interface.logger.error(f"æ›´æ–°æ¶ˆæ¯å¤±è´¥: {str(e)}")
            else:
                # å¦‚æœæ¶ˆæ¯è¶…é•¿ï¼Œåªæ›´æ–°æœ€åéƒ¨åˆ†
                try:
                    await thinking_message.edit_text(text[-MAX_MESSAGE_LENGTH:]
                                                     )
                except telegram.error.BadRequest as e:
                    # å¿½ç•¥"æ¶ˆæ¯æœªä¿®æ”¹"é”™è¯¯
                    if "Message is not modified" not in str(e):
                        _interface.logger.error(f"æ›´æ–°æ¶ˆæ¯å¤±è´¥: {str(e)}")

        except Exception as e:
            # å¿½ç•¥"æ¶ˆæ¯æœªä¿®æ”¹"é”™è¯¯
            if "Message is not modified" not in str(e):
                _interface.logger.error(f"æ›´æ–°æ¶ˆæ¯å¤±è´¥: {str(e)}")

    # è°ƒç”¨æµå¼ AI API
    response = await AIManager.call_ai_api(provider_id, messages, images, True,
                                           update_message_callback)

    # æ·»åŠ  AI å›å¤åˆ°ä¸Šä¸‹æ–‡
    ConversationManager.add_message(user_id, "assistant", response)

    # æµå¼ä¼ è¾“å®Œæˆåï¼Œå°è¯•å°†æœ€ç»ˆæ¶ˆæ¯è½¬æ¢ä¸º HTML æ ¼å¼
    try:
        # è½¬æ¢ä¸º HTML æ ¼å¼
        html_response = TextFormatter.markdown_to_html(response)

        # æ£€æŸ¥é•¿åº¦
        if len(html_response) <= MAX_MESSAGE_LENGTH:
            try:
                # ç›´æ¥æ›´æ–°åŸæ¶ˆæ¯ä¸º HTML æ ¼å¼
                await thinking_message.edit_text(html_response,
                                                 parse_mode="HTML")
            except telegram.error.BadRequest as e:
                # å¿½ç•¥"æ¶ˆæ¯æœªä¿®æ”¹"é”™è¯¯
                if "Message is not modified" not in str(e):
                    _interface.logger.error(f"è½¬æ¢ä¸º HTML æ ¼å¼å¤±è´¥: {str(e)}")
        else:
            # å¦‚æœ HTML å¤ªé•¿ï¼Œéœ€è¦åˆ†æ®µå‘é€
            # å…ˆåˆ é™¤åŸæ¶ˆæ¯
            await thinking_message.delete()

            # åˆ†æ®µå‘é€ HTML
            parts = []
            for i in range(0, len(html_response), MAX_MESSAGE_LENGTH):
                parts.append(html_response[i:i + MAX_MESSAGE_LENGTH])

            _interface.logger.info(f"æ¶ˆæ¯è¿‡é•¿ï¼Œå°†åˆ†ä¸º {len(parts)} æ®µå‘é€")

            # å‘é€ç¬¬ä¸€æ®µ
            first_message = await update.message.reply_text(parts[0],
                                                            parse_mode="HTML")

            # å‘é€å‰©ä½™æ®µè½
            for part in parts[1:]:
                await first_message.reply_text(part, parse_mode="HTML")

    except Exception as e:
        _interface.logger.error(f"è½¬æ¢ä¸º HTML æ ¼å¼å¤±è´¥: {e}")
        # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œä¿ç•™åŸå§‹çº¯æ–‡æœ¬æ¶ˆæ¯
        # ä¸éœ€è¦é¢å¤–æ“ä½œï¼Œå› ä¸ºæµå¼æ›´æ–°å·²ç»æ˜¾ç¤ºäº†å®Œæ•´çš„çº¯æ–‡æœ¬å“åº”

    _interface.logger.info(f"ç”¨æˆ· {user_id} ä½¿ç”¨ {provider_id} æœåŠ¡å•†è·å¾—äº† AI å›å¤")


async def handle_private_message(update: Update,
                                 context: ContextTypes.DEFAULT_TYPE) -> None:
    """å¤„ç†ç§èŠæ¶ˆæ¯ï¼Œç›´æ¥å›å¤ AI å›ç­”"""
    user_id = update.effective_user.id

    # æ£€æŸ¥æƒé™
    if not AIManager.is_user_authorized(user_id, context, "private"):
        # ä¸å›å¤éç™½åå•ç”¨æˆ·
        return

    # è·å–æ¶ˆæ¯å†…å®¹
    message_text = update.message.text

    # æ£€æŸ¥æ¶ˆæ¯é•¿åº¦
    if len(message_text) > MAX_MESSAGE_LENGTH:
        await update.message.reply_text(
            f"âš ï¸ æ¶ˆæ¯å¤ªé•¿ï¼Œè¯·å°†é•¿åº¦æ§åˆ¶åœ¨ {MAX_MESSAGE_LENGTH} å­—ç¬¦ä»¥å†…")
        return

    # æ£€æŸ¥é»˜è®¤æœåŠ¡å•†
    provider_id = _state["default_provider"]
    if not provider_id or provider_id not in _state["providers"]:
        await update.message.reply_text("âš ï¸ æœªé…ç½®é»˜è®¤ AI æœåŠ¡å•†ï¼Œè¯·è”ç³»ç®¡ç†å‘˜")
        _interface.logger.warning(f"ç”¨æˆ· {user_id} å°è¯•ä½¿ç”¨ AI ä½†æœªé…ç½®é»˜è®¤æœåŠ¡å•†")
        return

    # æ£€æŸ¥æ˜¯å¦æœ‰å›¾åƒ
    images = []
    if update.message.photo:
        provider = _state["providers"].get(provider_id, {})
        if provider.get("supports_image", False):
            # è·å–æœ€å¤§å°ºå¯¸çš„å›¾åƒ
            photo = update.message.photo[-1]
            photo_file = await context.bot.get_file(photo.file_id)

            # å¤„ç†å›¾åƒ
            image_data = await AIManager.process_image(photo_file)
            if image_data:
                images.append(image_data)
                # ä¸å‘é€ç¡®è®¤æ¶ˆæ¯ï¼Œä¿æŒå¯¹è¯æµç•…
        else:
            await update.message.reply_text("âš ï¸ å½“å‰æœåŠ¡å•†ä¸æ”¯æŒå›¾åƒå¤„ç†")
            return

    # å‘é€"æ­£åœ¨æ€è€ƒ"æ¶ˆæ¯
    thinking_message = await update.message.reply_text("ğŸ¤” æ­£åœ¨æ€è€ƒä¸­...")

    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°ä¸Šä¸‹æ–‡
    ConversationManager.add_message(user_id, "user", message_text)

    # å‡†å¤‡ API è¯·æ±‚
    messages = ConversationManager.format_for_api(provider_id, user_id)

    # å®Œæ•´å“åº”å˜é‡
    full_response = ""

    # åˆ›å»ºæµå¼æ›´æ–°å›è°ƒå‡½æ•°
    async def update_message_callback(text):
        nonlocal full_response
        try:
            # ç¡®ä¿æ–‡æœ¬ä¸ä¸ºç©º
            if not text.strip():
                return

            full_response = text

            # å¦‚æœæ–‡æœ¬å¤ªé•¿ï¼Œåªæ˜¾ç¤ºæœ€åéƒ¨åˆ†
            if len(text) <= MAX_MESSAGE_LENGTH:
                await thinking_message.edit_text(text)
            else:
                # å¦‚æœæ¶ˆæ¯è¶…é•¿ï¼Œåªæ›´æ–°æœ€åéƒ¨åˆ†
                await thinking_message.edit_text(text[-MAX_MESSAGE_LENGTH:])

        except Exception as e:
            # å¿½ç•¥"æ¶ˆæ¯æœªä¿®æ”¹"é”™è¯¯
            if "Message is not modified" not in str(e):
                _interface.logger.error(f"æ›´æ–°æ¶ˆæ¯å¤±è´¥: {e}")

    # è°ƒç”¨æµå¼ AI API
    response = await AIManager.call_ai_api(provider_id, messages, images, True,
                                           update_message_callback)

    # æ·»åŠ  AI å›å¤åˆ°ä¸Šä¸‹æ–‡
    ConversationManager.add_message(user_id, "assistant", response)

    # æµå¼ä¼ è¾“å®Œæˆåï¼Œå°è¯•å°†æœ€ç»ˆæ¶ˆæ¯è½¬æ¢ä¸º HTML æ ¼å¼
    try:
        # è½¬æ¢ä¸º HTML æ ¼å¼
        html_response = TextFormatter.markdown_to_html(response)

        # æ£€æŸ¥é•¿åº¦
        if len(html_response) <= MAX_MESSAGE_LENGTH:
            try:
                # ç›´æ¥æ›´æ–°åŸæ¶ˆæ¯ä¸º HTML æ ¼å¼
                await thinking_message.edit_text(html_response,
                                                 parse_mode="HTML")
            except telegram.error.BadRequest as e:
                # å¿½ç•¥"æ¶ˆæ¯æœªä¿®æ”¹"é”™è¯¯
                if "Message is not modified" not in str(e):
                    _interface.logger.error(f"è½¬æ¢ä¸º HTML æ ¼å¼å¤±è´¥: {str(e)}")
        else:
            # å¦‚æœ HTML å¤ªé•¿ï¼Œéœ€è¦åˆ†æ®µå‘é€
            # å…ˆåˆ é™¤åŸæ¶ˆæ¯
            await thinking_message.delete()

            # åˆ†æ®µå‘é€ HTML
            parts = []
            for i in range(0, len(html_response), MAX_MESSAGE_LENGTH):
                parts.append(html_response[i:i + MAX_MESSAGE_LENGTH])

            _interface.logger.info(f"æ¶ˆæ¯è¿‡é•¿ï¼Œå°†åˆ†ä¸º {len(parts)} æ®µå‘é€")

            # å‘é€ç¬¬ä¸€æ®µ
            first_message = await update.message.reply_text(parts[0],
                                                            parse_mode="HTML")

            # å‘é€å‰©ä½™æ®µè½
            for part in parts[1:]:
                await first_message.reply_text(part, parse_mode="HTML")

    except Exception as e:
        _interface.logger.error(f"è½¬æ¢ä¸º HTML æ ¼å¼å¤±è´¥: {e}")
        # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œä¿ç•™åŸå§‹çº¯æ–‡æœ¬æ¶ˆæ¯
        # ä¸éœ€è¦é¢å¤–æ“ä½œï¼Œå› ä¸ºæµå¼æ›´æ–°å·²ç»æ˜¾ç¤ºäº†å®Œæ•´çš„çº¯æ–‡æœ¬å“åº”

    _interface.logger.info(f"ç”¨æˆ· {user_id} åœ¨ç§èŠä¸­è·å¾—äº† AI å›å¤")


async def handle_private_photo(update: Update,
                               context: ContextTypes.DEFAULT_TYPE) -> None:
    """å¤„ç†ç§èŠä¸­çš„å›¾ç‰‡æ¶ˆæ¯"""
    user_id = update.effective_user.id

    # æ£€æŸ¥æƒé™
    if not AIManager.is_user_authorized(user_id, context, "private"):
        # ä¸å›å¤éç™½åå•ç”¨æˆ·
        return

    # æ£€æŸ¥é»˜è®¤æœåŠ¡å•†
    provider_id = _state["default_provider"]
    if not provider_id or provider_id not in _state["providers"]:
        await update.message.reply_text("âš ï¸ æœªé…ç½®é»˜è®¤ AI æœåŠ¡å•†ï¼Œè¯·è”ç³»ç®¡ç†å‘˜")
        _interface.logger.warning(f"ç”¨æˆ· {user_id} å°è¯•ä½¿ç”¨ AI ä½†æœªé…ç½®é»˜è®¤æœåŠ¡å•†")
        return

    # æ£€æŸ¥æœåŠ¡å•†æ˜¯å¦æ”¯æŒå›¾åƒ
    provider = _state["providers"].get(provider_id, {})
    if not provider.get("supports_image", False):
        await update.message.reply_text("âš ï¸ å½“å‰æœåŠ¡å•†ä¸æ”¯æŒå›¾åƒå¤„ç†")
        return

    # è·å–å›¾åƒ
    photo = update.message.photo[-1]  # æœ€å¤§å°ºå¯¸çš„å›¾åƒ
    photo_file = await context.bot.get_file(photo.file_id)

    # å¤„ç†å›¾åƒ
    image_data = await AIManager.process_image(photo_file)
    if not image_data:
        await update.message.reply_text("âŒ å¤„ç†å›¾åƒå¤±è´¥")
        return

    # è·å–æ¶ˆæ¯æ–‡æœ¬(å¦‚æœæœ‰)
    message_text = update.message.caption or "åˆ†æè¿™å¼ å›¾ç‰‡"

    # å‘é€"æ­£åœ¨æ€è€ƒ"æ¶ˆæ¯
    thinking_message = await update.message.reply_text("ğŸ–¼ï¸ æ­£åœ¨åˆ†æå›¾åƒ...")

    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°ä¸Šä¸‹æ–‡
    ConversationManager.add_message(user_id, "user", message_text)

    # å‡†å¤‡ API è¯·æ±‚
    messages = ConversationManager.format_for_api(provider_id, user_id)

    # å®Œæ•´å“åº”å˜é‡
    full_response = ""

    # åˆ›å»ºæµå¼æ›´æ–°å›è°ƒå‡½æ•°
    async def update_message_callback(text):
        nonlocal full_response
        try:
            # ç¡®ä¿æ–‡æœ¬ä¸ä¸ºç©º
            if not text.strip():
                return

            full_response = text

            # å¦‚æœæ–‡æœ¬å¤ªé•¿ï¼Œåªæ˜¾ç¤ºæœ€åéƒ¨åˆ†
            if len(text) <= MAX_MESSAGE_LENGTH:
                await thinking_message.edit_text(text)
            else:
                # å¦‚æœæ¶ˆæ¯è¶…é•¿ï¼Œåªæ›´æ–°æœ€åéƒ¨åˆ†
                await thinking_message.edit_text(text[-MAX_MESSAGE_LENGTH:])

        except Exception as e:
            # å¿½ç•¥"æ¶ˆæ¯æœªä¿®æ”¹"é”™è¯¯
            if "Message is not modified" not in str(e):
                _interface.logger.error(f"æ›´æ–°æ¶ˆæ¯å¤±è´¥: {e}")

    # è°ƒç”¨æµå¼ AI API
    response = await AIManager.call_ai_api(provider_id, messages, [image_data],
                                           True, update_message_callback)

    # æ·»åŠ  AI å›å¤åˆ°ä¸Šä¸‹æ–‡
    ConversationManager.add_message(user_id, "assistant", response)

    # æµå¼ä¼ è¾“å®Œæˆåï¼Œå°è¯•å°†æœ€ç»ˆæ¶ˆæ¯è½¬æ¢ä¸º HTML æ ¼å¼
    try:
        # è½¬æ¢ä¸º HTML æ ¼å¼
        html_response = TextFormatter.markdown_to_html(response)

        # æ£€æŸ¥é•¿åº¦
        if len(html_response) <= MAX_MESSAGE_LENGTH:
            try:
                # ç›´æ¥æ›´æ–°åŸæ¶ˆæ¯ä¸º HTML æ ¼å¼
                await thinking_message.edit_text(html_response,
                                                 parse_mode="HTML")
            except telegram.error.BadRequest as e:
                # å¿½ç•¥"æ¶ˆæ¯æœªä¿®æ”¹"é”™è¯¯
                if "Message is not modified" not in str(e):
                    _interface.logger.error(f"è½¬æ¢ä¸º HTML æ ¼å¼å¤±è´¥: {str(e)}")
        else:
            # å¦‚æœ HTML å¤ªé•¿ï¼Œéœ€è¦åˆ†æ®µå‘é€
            # å…ˆåˆ é™¤åŸæ¶ˆæ¯
            await thinking_message.delete()

            # åˆ†æ®µå‘é€ HTML
            parts = []
            for i in range(0, len(html_response), MAX_MESSAGE_LENGTH):
                parts.append(html_response[i:i + MAX_MESSAGE_LENGTH])

            _interface.logger.info(f"æ¶ˆæ¯è¿‡é•¿ï¼Œå°†åˆ†ä¸º {len(parts)} æ®µå‘é€")

            # å‘é€ç¬¬ä¸€æ®µ
            first_message = await update.message.reply_text(parts[0],
                                                            parse_mode="HTML")

            # å‘é€å‰©ä½™æ®µè½
            for part in parts[1:]:
                await first_message.reply_text(part, parse_mode="HTML")

    except Exception as e:
        _interface.logger.error(f"è½¬æ¢ä¸º HTML æ ¼å¼å¤±è´¥: {e}")
        # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œä¿ç•™åŸå§‹çº¯æ–‡æœ¬æ¶ˆæ¯
        # ä¸éœ€è¦é¢å¤–æ“ä½œï¼Œå› ä¸ºæµå¼æ›´æ–°å·²ç»æ˜¾ç¤ºäº†å®Œæ•´çš„çº¯æ–‡æœ¬å“åº”

    _interface.logger.info(f"ç”¨æˆ· {user_id} åœ¨ç§èŠä¸­è·å¾—äº†å›¾åƒåˆ†æå›å¤")


# é…ç½®å’ŒçŠ¶æ€ç®¡ç†å‡½æ•°


def save_config() -> None:
    """ä¿å­˜ AI é…ç½®"""
    global _state

    config_to_save = {
        "providers": _state["providers"],
        "whitelist": _state["whitelist"],
        "default_provider": _state["default_provider"],
        "usage_stats": _state["usage_stats"],
        "conversation_timeout": _state.get("conversation_timeout",
                                           24 * 60 * 60)
    }

    os.makedirs(os.path.dirname(CONFIG_FILE), exist_ok=True)

    try:
        with open(CONFIG_FILE, 'w', encoding='utf-8') as f:
            json.dump(config_to_save, f, ensure_ascii=False, indent=2)
    except Exception as e:
        if _interface:
            _interface.logger.error(f"ä¿å­˜ AI é…ç½®å¤±è´¥: {e}")


def load_config() -> None:
    """åŠ è½½ AI é…ç½®"""
    global _state

    if not os.path.exists(CONFIG_FILE):
        # åˆå§‹åŒ–ç©ºç»“æ„
        _state["providers"] = {}
        _state["whitelist"] = []
        _state["default_provider"] = None
        _state["usage_stats"] = {
            "total_requests": 0,
            "requests_by_provider": {},
            "requests_by_user": {}
        }
        _state["conversation_timeout"] = 24 * 60 * 60  # é»˜è®¤ 24 å°æ—¶

        # åˆ›å»ºé…ç½®æ–‡ä»¶
        save_config()
        return

    try:
        with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
            config = json.load(f)

            # åŠ è½½æä¾›å•†é…ç½®
            if "providers" in config:
                _state["providers"] = config["providers"]

            # åŠ è½½ç™½åå•
            if "whitelist" in config:
                _state["whitelist"] = config["whitelist"]

            # åŠ è½½é»˜è®¤æä¾›å•†
            if "default_provider" in config:
                _state["default_provider"] = config["default_provider"]

            # åŠ è½½ä½¿ç”¨ç»Ÿè®¡
            if "usage_stats" in config:
                _state["usage_stats"] = config["usage_stats"]

            # åŠ è½½å¯¹è¯è¶…æ—¶è®¾ç½®
            if "conversation_timeout" in config:
                _state["conversation_timeout"] = config["conversation_timeout"]
    except Exception as e:
        if _interface:
            _interface.logger.error(f"åŠ è½½ AI é…ç½®å¤±è´¥: {e}")


def save_contexts() -> None:
    """ä¿å­˜æ‰€æœ‰ç”¨æˆ·çš„å¯¹è¯ä¸Šä¸‹æ–‡"""
    try:
        os.makedirs(os.path.dirname(CONTEXT_FILE), exist_ok=True)
        with open(CONTEXT_FILE, 'w', encoding='utf-8') as f:
            json.dump(_state["conversations"], f, ensure_ascii=False, indent=2)

        # æ›´æ–°ä¿å­˜æ—¶é—´
        _state["last_save_time"] = time.time()
    except Exception as e:
        if _interface:
            _interface.logger.error(f"ä¿å­˜å¯¹è¯ä¸Šä¸‹æ–‡å¤±è´¥: {e}")


def load_contexts() -> None:
    """åŠ è½½æ‰€æœ‰ç”¨æˆ·çš„å¯¹è¯ä¸Šä¸‹æ–‡"""
    global _state

    if not os.path.exists(CONTEXT_FILE):
        return

    try:
        with open(CONTEXT_FILE, 'r', encoding='utf-8') as f:
            _state["conversations"] = json.load(f)
    except Exception as e:
        if _interface:
            _interface.logger.error(f"åŠ è½½å¯¹è¯ä¸Šä¸‹æ–‡å¤±è´¥: {e}")


# æ¨¡å—çŠ¶æ€ç®¡ç†å‡½æ•°


def get_state(module_interface):
    """è·å–æ¨¡å—çŠ¶æ€ï¼ˆç”¨äºçƒ­æ›´æ–°ï¼‰"""
    module_interface.logger.debug("æ­£åœ¨è·å– AI æ¨¡å—çŠ¶æ€ç”¨äºçƒ­æ›´æ–°")

    # åªè¿”å›å¯åºåˆ—åŒ–çš„çŠ¶æ€æ•°æ®
    serializable_state = {
        "providers":
        _state["providers"].copy() if "providers" in _state else {},
        "whitelist":
        _state["whitelist"].copy() if "whitelist" in _state else [],
        "conversations":
        _state["conversations"].copy() if "conversations" in _state else {},
        "default_provider": _state.get("default_provider"),
        "usage_stats":
        _state["usage_stats"].copy() if "usage_stats" in _state else {
            "total_requests": 0,
            "requests_by_provider": {},
            "requests_by_user": {}
        },
        "conversation_timeout": _state.get("conversation_timeout",
                                           24 * 60 * 60),
        # æ˜¾å¼æ’é™¤ä¸å¯åºåˆ—åŒ–å¯¹è±¡
        # "concurrent_requests": _state.get("concurrent_requests", 0),
        # "request_lock": None,  # é”ä¸å¯åºåˆ—åŒ–
    }

    return serializable_state


# ä¿®æ”¹ ai.py ä¸­çš„ set_state å‡½æ•°
def set_state(module_interface, state):
    """è®¾ç½®æ¨¡å—çŠ¶æ€ï¼ˆç”¨äºçƒ­æ›´æ–°ï¼‰"""
    global _state

    # åˆ›å»ºæ–°çš„çŠ¶æ€å¯¹è±¡
    new_state = {}

    # ä»ä¿å­˜çš„çŠ¶æ€ä¸­å¤åˆ¶å¯åºåˆ—åŒ–éƒ¨åˆ†
    new_state["providers"] = state.get("providers", {})
    new_state["whitelist"] = state.get("whitelist", [])
    new_state["conversations"] = state.get("conversations", {})
    new_state["default_provider"] = state.get("default_provider")
    new_state["usage_stats"] = state.get("usage_stats", {
        "total_requests": 0,
        "requests_by_provider": {},
        "requests_by_user": {}
    })
    new_state["conversation_timeout"] = state.get("conversation_timeout",
                                                  24 * 60 * 60)

    # åˆå§‹åŒ–è¿è¡Œæ—¶çŠ¶æ€
    new_state["concurrent_requests"] = 0
    new_state["request_lock"] = asyncio.Lock()

    # æ›¿æ¢æ•´ä¸ªçŠ¶æ€å¯¹è±¡
    _state = new_state

    module_interface.logger.debug("å·²æ¢å¤ AI æ¨¡å—çŠ¶æ€")


async def setup(module_interface):
    """æ¨¡å—åˆå§‹åŒ–"""
    global _interface, _state
    _interface = module_interface

    # åˆå§‹åŒ–è¯·æ±‚é”
    _state["request_lock"] = asyncio.Lock()

    # ä»æŒä¹…åŒ–å­˜å‚¨åŠ è½½çŠ¶æ€
    saved_state = module_interface.load_state(default={})
    if saved_state:
        set_state(module_interface, saved_state)
    else:
        # å¦‚æœæ²¡æœ‰ä¿å­˜çš„çŠ¶æ€ï¼ŒåŠ è½½é…ç½®æ–‡ä»¶
        load_config()
        load_contexts()

    # æ³¨å†Œå‘½ä»¤
    await module_interface.register_command("aiconfig",
                                            ai_config_command,
                                            admin_level="super_admin",
                                            description="é…ç½® AI è®¾ç½®")

    await module_interface.register_command("aiwhitelist",
                                            ai_whitelist_command,
                                            admin_level="super_admin",
                                            description="ç®¡ç† AI ç™½åå•")

    await module_interface.register_command("aiclear",
                                            ai_clear_command,
                                            admin_level=False,
                                            description="æ¸…é™¤ AI å¯¹è¯å†å²")

    await module_interface.register_command("ai",
                                            ai_command,
                                            admin_level=False,
                                            description="å‘ AI å‘é€æ¶ˆæ¯")

    # æ³¨å†Œç§èŠæ¶ˆæ¯å¤„ç†å™¨
    text_handler = MessageHandler(
        filters.TEXT & filters.ChatType.PRIVATE & ~filters.COMMAND
        & ~filters.Regex(r'^/'), handle_private_message)
    await module_interface.register_handler(text_handler)

    # æ³¨å†Œç§èŠå›¾ç‰‡å¤„ç†å™¨
    photo_handler = MessageHandler(filters.PHOTO & filters.ChatType.PRIVATE,
                                   handle_private_photo)
    await module_interface.register_handler(photo_handler)

    # è®¾ç½®å®šæœŸä»»åŠ¡
    async def _periodic_tasks():
        while True:
            try:
                # æ¯å°æ—¶æ£€æŸ¥ä¸€æ¬¡è¿‡æœŸå¯¹è¯
                await asyncio.sleep(3600)
                expired_count = ConversationManager.cleanup_expired()
                if expired_count > 0:
                    _interface.logger.info(f"å·²æ¸…ç† {expired_count} ä¸ªè¿‡æœŸå¯¹è¯")

                # ä¿å­˜çŠ¶æ€ - ç¡®ä¿è·å–æ¸…ç†è¿‡çš„çŠ¶æ€
                serializable_state = get_state(module_interface)
                module_interface.save_state(serializable_state)
                save_contexts()
                _interface.logger.debug("å·²å®šæœŸä¿å­˜ AI æ¨¡å—çŠ¶æ€")
            except Exception as e:
                _interface.logger.error(f"å®šæœŸä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(e)}")

    # å¯åŠ¨å®šæœŸä»»åŠ¡
    module_interface.periodic_task = asyncio.create_task(_periodic_tasks())

    _interface.logger.info(f"æ¨¡å— {MODULE_NAME} v{MODULE_VERSION} å·²åˆå§‹åŒ–")


async def cleanup(module_interface):
    """æ¨¡å—æ¸…ç†"""
    # å–æ¶ˆå®šæœŸä»»åŠ¡
    if hasattr(module_interface,
               'periodic_task') and module_interface.periodic_task:
        module_interface.periodic_task.cancel()

    # ä¿å­˜çŠ¶æ€ - ä½¿ç”¨ get_state è·å–å¯åºåˆ—åŒ–çŠ¶æ€
    module_interface.save_state(get_state(module_interface))
    save_contexts()

    module_interface.logger.info(f"æ¨¡å— {MODULE_NAME} å·²æ¸…ç†")
